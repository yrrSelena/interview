[TOC]


字节客户端面试



> [字节跳动-客户端开发工程师-产品研发和工程架构部职位的面试（二面）](https://blog.csdn.net/weixin_44343282/article/details/106170594)
> [字节跳动 客户端实习生 已拿offer（C++）](https://www.nowcoder.com/discuss/382896)
> [字节跳动提前批 客户端 二面凉经 C++](https://www.nowcoder.com/discuss/446444?type=post&order=time&pos=&page=1&channel=666&source_id=search_post&subType=2)

一面： 


#### 

Linux

yum在centos

Docker

**Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。**它是目前最流行的 Linux 容器解决方案。

Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。

总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。

docker是一个开源的应用容器引擎，开发者可以打包自己的应用到容器里面，然后迁移到其他机器的docker应用中，可以实现快速部署。如果出现的故障，可以通过镜像，快速恢复服务。

##### 用途

**（1）提供一次性的环境。**比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。

**（2）提供弹性的云服务。**因为 Docker 容器可以随开随关，很适合动态扩容和缩容。

**（3）组建微服务架构。**通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。



## 操作系统

### 1. 概述 

#### OS运行级别（用户态 内核态）

两种CPU状态 

1. 内核态
   - 可以执行任何cpu指令，也可以引用任何内存地址，包括外围设备, 例如硬盘, 网卡，权限等级最高。
   - 当一个任务（进程）执行系统调用而陷入内核代码中执行时，进程处于内核运行态。操作系统运行在内核态
2. 用户态
   - 只能受限地访问内存，且不允许访问外围设备。在执行cpu指令的时候也可以被高优先级抢占。
   - 所有用户程序都在用户态运行，但有时程序需要做一些内核态的事（如从硬盘读取数据、从键盘获取输入等）

意义：需要限制不同程序之间的访问能力，防止它们获取别的程序的内存数据或外围设备的数据，并发送到网络

CPU指令：特权指令、非特权指令
特权指令：只能由操作系统内核部分使用，而不允许用户直接使用的指令（如I/O指令、置终端屏蔽指令、清内存、建存储保护、设置时钟指令）
非特权指令：所有程序均可直接使用

#### 中断

中断是CPU从用户态切换为内核态的唯一途径，让操作系统获得计算机的控制权。有了中断才能实现多道程序并发执行

内核态->用户态：执行一个特权指令，将程序状态字（PSW）的标志位设为“用户态”
用户态->内核态：**中断**（内中断[中断信号来自CPU内部，与当前执行的指令有关]、外中断）

1. 系统调用
   用户态进程主动要求切换到内核态。eg. fork()执行创建新进程的系统调用；Linux的int80h中断
2. 强迫中断（硬件故障、软件中断）
   CPU执行运行在用户态的程序时，发生某些不可预知的异常，会触发由当前运行进程切换到处理此异常的内核相关程序中。eg. 缺页异常（硬件故障），除以0（软件中断）
3. 外中断
   当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，此时CPU会暂停执行下一条即将执行的指令，转而去执行与中断信号对应的处理程序。eg. 硬盘I/O操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作（外设请求）、用户强行终止一个进程（人工干预）



内核的功能
（1） I/O指令、置终端屏蔽指令、清内存、建存储保护、设置时钟指令。
（2） 中断、异常、陷入，比如缺页中断、除以0、I/O中断等
（3）进程（线程）管理（进程或线程的调度）
（4）系统调用，比如调用了设备驱动程序
（5）用户内存地址的转换（逻辑---> 物理地址映射）

### 2. 进程管理

#### 进程和线程▲ 

>[图解进程线程](http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html)

1. 进程是操作系统资源分配的最小单位，线程是CPU任务调度的最小单位。
2. 一个进程可以有多个线程，一个线程只属于一个进程
3. 数据共享：不同进程间数据很难共享<共享内存>，同一进程下不同线程间数据很易共享。
   - 系统在运行的时候会为每个进程分配不同的内存空间，每个进程都有独立的代码和数据空间。
   - 线程可以看做轻量级的进程，除了CPU外，系统不会为线程分配内存，同一类线程共享代码和数据空间。
4. 系统开销：进程创建销毁开销大，线程创建销毁开销小
   - 创建/撤销进程时，系统都要为之分配/回收资源（内存空间、I/O设备等），进程间切换涉及当前执行进程CPU环境保存即新调度进程CPU环境的设置
   - 每个线程都有自己独立的运行栈和程序计数器，线程切换只需保存和设置少量寄存器内容，开销小
5. 通信：进程间通过IPC（Inter-Process communication，进程间通信）通信，线程可以通过读写数据段直接与进程内的其它线程通信
6. 进程间不会相互影响，一个进程报错不会影响其他进程正常运行，一个线程出错会导致同属该进程的线程停止运行。
7. 进程调试简单，线程调试较为复杂




#### 进程的状态与转换

**三种状态**：运行、就绪、等待

- 运行：进程占有CPU，并在CPU上执行其程序

- 就绪：进程已获得除CPU外的资源，只差CPU 【等待CPU】“万事俱备，只欠CPU”

- 等待/阻塞：进程由于某些原因（I/O请求，申请缓存区失败）而不能继续运行下去，进程受到阻塞【等待除CPU外的其它资源】
  
  ![img](https://img2018.cnblogs.com/blog/1330620/201809/1330620-20180915131910362-1573414576.png)

**状态转换**

- 就绪态→运行态：进程被调度后，分配CPU时间片，并使其运行
- 运行态→就绪态。进程时间片用完后，让出CPU，转为就绪态
- 运行态→阻塞态。进程请求某一资源或等待某一事件发生（如I/O完成，需要人工干预），使自身阻塞
- 阻塞态→就绪态。进程等待的事件到来时，如I/O操作结束，转为就绪态

**进程切换**

1. 对原来运行进程各种数据的保存

2. 对新进程各种数据的回复

   如程序计数器PC、程序状态字、各种数据寄存器等处理机现场信息（一般保存在进程控制块中PCB）

#### CPU上下文切换

ＣPU寄存器(CPU内置的容量小但速度极快的内存)和程序计数器(用于存储CPU正在执行的指令位置或即将执行的下一条指令位置)

CPU上下文切换：进程上下文切换、线程上下文切换、中断上下文切换

1. 进程上下文切换：
   - 进程由内核管理调度，进程切换发生在内核态。只有进程调度的是否才需要切换上下文
   - 进程的上下文包括虚拟内存、栈、全局变量等用户空间的资源，还包括内核堆栈、寄存器等内核空间的状态。
   - 进程上下文切换：保存当前进程的虚拟内存、栈等->保存内核状态和CPU寄存器->加载下个进程得到内核态->加载下个进程的虚拟内存和用户栈

2. 线程上下文切换：

   - 两个线程同属于一个进程：此时虚拟内存是共享的，因此在切换时，只需要切换线程私有的数据、寄存器等不共享的资源，虚拟内存等共享资源保持不变
   - 两个线程不属于一个进程：类似于进程上下文切换

3. 中断上下文切换：

   许多操作系统的中断服务程序都不在进程上下文中执行，它们在一个与所有进程无关的、专门的中断上下文中执行。之所以存在这样一个专门的执行环境，为了保证中断服务程序能够在第一时间响应和处理中断请求，然后快速退出。
   
   **系统调用**是特权模式切换，会发生CPU上下文切换：
   
   - 保存CPU寄存器原来用户态的指令位置，将CPU寄存器更新为内核态指令的新位置，然后跳转到内核态运行内核任务。系统调用结束后，CPU寄存器恢复原来用户保存的状态，再切换到用户空间，继续运行进程。
   - 一次系统调用发生了两次CPU上下文切换
   - 系统调用不涉及虚拟内存等进程用户态的资源，也不会切换进程（系统调用一直在同一个进程中运行）

#### 孤儿进程  僵尸进程

> https://blog.csdn.net/u013616945/article/details/77606449

孤儿进程：没有父进程的进程。父进程退出，而它的子进程还在运行，这些子进程就会成为孤儿进程。这些子进程会被进程号为1的init进程收养，对它们完成状态收集工作

僵尸进程：子进程退出，而父进程没有调用wait或waitpid获取子进程的状态信息，子进程的进程描述符还保留在系统中。进程在调用exit命令结束自己生命的时候没有被完全销毁，而仅仅是退出（会造成资源浪费）

1. 信号机制：子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。
2. 两次fork()，让子进程变成孤儿进程，其父进程变为init进程，通过init进程处理僵尸进程

守护进程：脱离终端，在后台执行的进程



#### 线程创建

C++：thread

thread()创建一个新的线程，可以接收任意可调用对象类型，包括**函数、函数指针、lambda表达式、函数对象（重载了函数调用运算符的类对象）**

```cpp
#include <iostream>
#include<thread>
#include<string>
using namespace std;

void func(string s){
    cout<<s<<endl;
}

class A{
public:
    void operator()(int i,string s){
        cout<<s<<endl;
    }
};


int main()
{
    thread funcThread(func,"用函数创建线程");
    funcThread.join();

    void (*pfunc)(string s); //= func;
    pfunc=func;
    thread pfuncThread(pfunc,"用函数指针创建线程");
    pfuncThread.join();


    A a;
    thread operatorThread(a,1,"用仿函数创建线程");
    operatorThread.join();

    auto lambdaFunc = [](string s){cout<<s<<endl;};
    thread lambdaThread(lambdaFunc,"用Lambda函数创建线程 ");
    lambdaThread.join();
	
    //用某个类中的某个函数作为线程的入口地址==未完

    cout<<"主线程"<<endl;
    return 0;
}
```




#### 线程共享与独占的资源

- 共享的资源有：
  1. **堆**：由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）
  2. **全局变量**：它与具体某一函数无关的，所以也与特定线程无关；因此也是共享的
  3. **静态变量**：虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的
  4. **文件等公用资源**：这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。
- 独享的资源有：
  1. **栈**：保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立，因此栈是thread safe的。操作系统在切换线程的时候会自动的切换栈，就是切换SS/ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。
  2. **寄存器**  包括**程序计数器PC**，存放执行流的基本数据（执行流：一段逻辑上独立的指令区域）
  3. 线程局部存储（TLS）某些操作系统为线程单独提供的私有空间，容量有限。可存储线程中的一个全局变量

栈（堆栈）：主线程的main函数、进行函数调用的参数和返回地址、局部变量等内容都会被压入栈内
PC（Program Couner）：程序计数器，PC的指针指向代码所在的内存地址。

1. 字节码解释器通过改变程序计数器来继续读取指令，从而实现代码的流程控制
2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候，能够知道该线程上次运行到什么位置
   



#### 线程 join vs detach

join：1.主线程要等待子线程执行完毕才会继续向下执行，是一个阻塞函数 2.回收该线程中使用的资源

detach：线程被分离到后台运行，主线程不需要等待线程结束才结束（守护线程）

> 主线程不用等待子线程执行完毕，两者脱离关系。将当前线程对象所代表的执行实例与该线程对象分离，使得线程的执行可以单独进行。此线程将放在后台运行，所有权和控制权被转交给`C++`运行时库，以确保与线程相关联的资源在线程退出后能被正确的回收。一旦线程执行完毕，它所分配的资源将会被释放。一般用在**守护线程**上：有时候我们需要建立一个暗中观察的线程，默默查询程序的某种状态，这种的称为守护线程。这种线程会在主线程销毁之后自动销毁。线程被分离之后，即使该线程对象被析构了，线程还是能够在后台运行，只是由于对象被析构了，主线程不能够通过对象名与这个线程进行通信。

**线程对象和对象内部管理的线程的生命周期并不一样**，如果线程执行的快，可能内部的线程已经结束了，但是线程对象还活着，也有可能线程对象已经被析构了，内部的线程还在运行。

##### [拓] wait()和sleep()

（1）属于不同的两个类，sleep()方法是线程类（Thread）的静态方法，wait()方法是Object类里的方法。
（2）sleep()方法不会释放锁，wait()方法释放对象锁。
（3）sleep()方法可以在任何地方使用，wait()方法则只能在同步方法或同步块中使用。
（4）sleep()使线程进入阻塞状态（线程睡眠），wait()方法使线程进入等待队列（线程挂起），也就是阻塞类别不同。

#### 进程调度

按分配处理器的方式，进程调度有两种方式：

1. 非抢占方式：一旦进程占用CPU就一直运行，直到终止或等待。
2. 抢占方式：系统强行剥夺已分配给现运行进程的CPU，而重新分配给其他进程运行。

抢占原则：时间片原则；优先权原则；短作业（进程）优先原则。

1. **先来先服务调度算法（FCFS）- 非抢占**：先进入队列的先提供服务
   有利于长进程的执行，而不利于短进程，有利于计算密集型进程(CPU密集型)，而不利于I/O密集型进程。不会出现饥饿现象

2. **最短作业优先算法（SJF）- 非抢占**：对执行时间最短的进程优先分派处理器。
   相比于FCFS算法，SJF算法可改善平均周转时间和平均带权周转时间，缩短进程的等待时间，提高系统的吞吐量（在单位时间内CPU从存储设备读取->处理->存储信息的量）。
   对长进程非常不利，可能长时间不能执行（产生饥饿现象），而且不能根据进程的紧迫程度来划分进程执行的优先级，也很难准确预计进程的执行时间，从而降低调度性能。

3. **最短剩余时间优先（SRTF）- 抢占（进程到达时）**：此时哪个进程剩余的作业时间最短就优先执行该进程

4. **高响应比优先调度算法（HRRN）- 非抢占**
   等待时间=上一个作业的完成时刻-该作业到达的时刻
   响应比=（等待时间+服务时间）/服务时间=等待时间/服务时间+1

  只有当前运行的作业/进程主动放弃CPU时，才需要计算响应比进行调度。综合考虑了等待时间和运行时间，不会导致饥饿

5. **时间片轮转算法（RR）- 抢占（时间片）**：根据一定的时间片轮流执行每个进程。
   每个进程都被分配好一个时间段，也就是它的时间片，这就是该进程允许允许的时间。如果该进程超过了时间片的时间，就会发生时间中断，调度程序暂停当前进程的执行，将其送到就绪队列的末尾，并通过上下文切换执行当前的队首进程。进程可以未使用完一个时间片，就让出CPU（如阻塞）。
   算法优点：时间片轮转调度算法的优点是简单易行，平均响应时间短。
   算法缺点：不利于处理紧急进程。在时间片轮转算法中，时间片的大小对系统性能的影响很大，因此时间片的大小要选择恰当。

   仅用于进程调度（只有作业放入内存建立了相应的进程后，才能被分配CPU时间片）

6. **优先级调度**：调度时选择优先级最高的作业/进程，会导致饥饿

   可用于进程、作业、I/O调度

7. **多级反馈队列调度算法- 抢占（时间片）**

   - 按优先级设置多个就绪进程队列
   - 按优先级（或就绪队列）设置不同的时间片 
   - 各级就绪队列按FIFO组织，FCFS调度，每个进程被调度后运行一个当前队列的时间片长度。（如果没有完成就降低它的优先级，到下一个就绪队列中等待服务。 当低优先级队列中的一个进程正在占用 CPU 进行运行，但是此时高优先级队列中有一个新的进程进入，低优先级进程就需要退回到队列中，让新高优先级进程运行完成再继续运行。）
   - 最后一级按循环轮转方式组织调度
   - 会导致饥饿

各类操作系统对调度方式的选择：

- 批处理系统：无须及时的用户响应，采用**不可抢占**的调度方式，或**时间间隔很长的可抢占调度方式**，从而允许进程能长时间运行，减少进程的切换次数，提高系统的性能；
- 交互式系统：及时的用户响应非常重要，必须采用可抢占的调度方式。以防单个进程占用太多CPU时间，影响到其他进程的运行。（**基于时间片的抢占方式**）
- 实时系统：对响应时间要求苛刻，每个进程运行时间很短，可采用可抢占的调度方式。（**基于优先权的可抢占方式**）

#### 进程通信与线程通信

> 进程之间和线程之间是怎么通信的? [字客1] 
>
> 线程间共享内存通信有没有什么要注意的点 [字客1]

##### 进程通信方式▲

>  [进程间的五种通信方式介绍](https://www.cnblogs.com/zgq0/p/8780893.html)
>
>  [进程间通信及使用场景](https://www.jianshu.com/p/4989c35c9475)

1.无名管道(pipe)，2.命名管道（FIFO），3.消息队列(msg)，4.共享内存(shm)，5.信号量(sem)，6.信号(signal)，7.套接字（socket）

1. 无名管道：
   - 半双工<单向通信>，即数据只能在一个方向上流动，具有固定的读端和写端（若双方要同时收发数据需要两个管道）
   - 只能用于具有亲缘关系的进程之间的通信（父子进程或兄弟进程之间）
   - 可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于**内存**中，缓冲区有限。
   - 相关接口：`int pipe(int fd[2]); //fd[0]读，fd[1]写`
2. 命名管道（FIFO是一种**文件**类型）
   - 是FIFO文件，存在于文件系统中，通过文件路径名指出
   - 可以在任意关系的进程间交换数据，与无名管道不同
   - FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且“先进先出”。
   - 常用于“客户—服务器”应用程序，FIFO用作**汇聚点**，在客户进程和服务器进程之间传递数据。`write_fifo`的作用类似于客户端，可以打开多个客户端向一个服务器发送请求信息，`read_fifo`类似于服务器，它实时监控着FIFO的读端，当有数据时，读出并进行处理。前提：每一个客户端必须预先知道服务器提供的FIFO接口
   - 相关接口：`int mkfifo(const char *pathname, mode_t mode); // pathname：FIFO文件路径，mode：和open()中的参数相同`
3. 消息队列：
   - 消息队列，是**消息的链接表**，存放在**内核**中（只有在内核重启或显式删除一个消息队列时才会被真正删除）。一个消息队列由一个标识符（即队列ID）来标识。
   - 将数据分成了一个个独立的数据单位，每个数据单位为一个消息体。每个消息体都是固定大小的存储块，在字节流上不连续（vs管道<字节流上连续>）
   - 可以实现任意进程间的通信，通过系统调用函数来实现消息发送和接收之间的同步
   - 面向记录，其中的消息具有特定的格式以及特定的优先级。
   - 独立于发送和接受进程。进程终止时，消息队列及其内容不会被删除
   - 可以实现消息的随机查询，消息不一定要以先进先出的次序读取，可以按消息的类型读取
   - 消息结构体被发送的时候，只是发送了消息结构体中成员的值，如果结构体成员是指针，并不会将指针所指向的空间的值发送，而只是发送了指针变量所保存的地址值。数组作为消息体结构体成员是可以的。因为整个数组空间都在消息体结构体中
   - 缺：信息的复制需要额外消耗CPU时间，不适合信息量大或操作频繁的场合
4. 信号量：

   - 信号量是一个**计数器**，信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
   - 用于进程间同步，若要在进程间传递数据，需要结合共享内存
   - 信号量基于操作系统的PV操作，程序对信号量的操作都是原子操作
   - 每次对信号量的PV操作不仅限于对信号量值+1/-1，也可以加减任意正整数
   - 支持信号量组
   - 多线程同步的信号量是POSIX信号量， 而在进程里使用SYSTEM V信号量。
   - 相关接口：`创建信号量：int semget(key_t key, int nsems, int semflag);`   `改变信号量值：int semop(int semid, struct sembuf *sops, unsigned nsops);`   `直接控制信号量信息：int semctl(int semid, int semnum, int cmd, union semun arg);` 
5. 共享内存：
   - 共享内存指两个或多个进程共享一个给定的存储区，多个进程可以同时操作，需要用信号量同步对共享内存的访问。
   - 最快的一种IPC，进程直接对内存进行存取，不存在读取文件、消息传递等过程
   - 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，因此只能同一个计算机系统中的进程进行共享，难以进行网络通信
   - 原理：系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。通过让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。
   - 相关接口：`创建共享内存：int shmget(key_t key, int size, int flag);` ; `连接到共享内存地址空间：void *shmat(int shmid, void *addr, int flag);` ; `从共享内存分离：int shmdt(const void *shmaddr);`
   - 共享内存的方式类似于多线程中线程对全局变量的访问，大家都对等地有权去修改这块内存的值，这就导致在多进程并发下，最终结果是不可预期的。所以对这块临界区的访问需要通过信号量来进行进程同步。
6. 信号：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
7. socket
   - TCP/IP的抽象接口，可用于**不同计算机间**的进程通信
   - 传输数据为字节级，传输数据可自定义，数据量小、效率高
   - 可以加密，数据安全性强
   - server端：[1.socket]申请一个socket->[2.bind]将socket登记到固定位置->[3.listen]等待client连接->[4.accept]接受用户连接申请->[5.read/write]进行数据交换->[6.close]关闭连接
   - client端：[1.socket]申请一个socket->[2.connect]与server连接->[3.read/write]进行数据交换->[4.close]关闭连接
   - 微信APP与其服务器通信，采用socket套接字进行通信。
   - 应用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务

|                  | 优缺点                                                       |
| ---------------- | ------------------------------------------------------------ |
| 匿名管道         | 速度慢，容量有限，单向通信，只有父子/兄弟进程能通讯          |
| FIFO（命名管道） | 任何进程间都能通讯，但速度慢                                 |
| 消息队列         | 容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题（可实现多对多，需在内存中实现） |
| 信号量           | 不能传递复杂消息，只能用来同步                               |
| 共享内存区       | 能够很容易控制容量，速度快，但要保持同步                     |
| socket           | 能够实现网络中进程间通信                                     |



##### 线程通信方式

- 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
- 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
- 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

#### 进程同步

同步：一个进程访问数据未结束时，其他进程不得对同一数据进行访问

##### 生产者消费者

系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者每次从缓冲区中取出一个产品并使用。

生产者、消费者共享一个初始为空、大小为n的缓冲区。

只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待

只有缓冲区不空时，消费者才能从缓冲区取产品，否则必须等待。

缓冲区时临界资源，各进程必须互斥地访问

互斥信号量：初值一般为1

同步信号量：初值要看对应资源的初值是多少

```cpp
semaphore mutex=1; //互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n; //同步信号量，表示空闲缓冲区的数量
semaphore full = 0; //同步信号量，表示产品的数量，即非空缓冲区的数量

producer(){
    while(1){
        生产一个产品;
        P(empty); //消耗一个空闲缓冲区
        P(mutex); //需要访问临界资源  【注】实现同步的P操作在实现互斥的P操作之前，否则会死锁
        把产品放入缓冲区;
        V(mutex);//V操作的顺序可换
        V(full);//缓冲区中增加一个产品
    }
}
consumer(){
    while(1){
        P(full); //消耗一个产品
        P(mutex);
        从缓冲区中取出一个产品;
        V(mutex);
        V(empty);
        使用产品;
    }
}
```

##### 哲学家进餐

一张圆桌上坐5位哲学家，每两个哲学家之间的放一根筷子。当哲学家饥饿的时候会试图拿起左右两根筷子（一根根拿）。如果筷子已经在别人手上，则需等待。只有同时拿起两根筷子才可以开始进餐，进餐完毕后放下筷子继续思考。

防止死锁发生：

1. 最多允许4个哲学家同时进餐，保证至少有一个哲学家可以同时拿到左右两只筷子
2. 要求奇数号的哲学家先拿左边的筷子，再拿右筷子，偶数号的哲学家恰好相反。保证如果相邻的两个哲学家都想吃饭，只有其中一个可以拿起第一只筷子，另一个位直接阻塞。避免了占有一只筷子后等待另一只的情况

#### 死锁

##### 死锁 vs 饥饿

- 饥饿：可能只有一个进程发生饥饿。可能在阻塞态（长期得不到所需的I/O设备），可能在就绪态（长期得不到CPU）
- 死锁：一定是“循环等待对方手里的资源”导致的，因此至少有两个或以上的进程同时发生死锁。发生死锁一定在阻塞态

两者都是由于操作系统资源分配策略不合理导致的

##### 死锁的必要条件▲

1. 互斥条件：只有对必须互斥使用的资源进行争抢才会导致死锁
2. 不剥夺条件：进程所获资源在未使用完之前不能被其他进程强行夺走
3. 请求和保持条件：进程已经保持了至少一个资源，但又提出新的资源请求，而该资源被其他进程占有。此时请求进程被阻塞，但又对自己已有的资源保持不放
4. 循环等待条件：存在一种进程资源的循环等待链（发生死锁一定有循环等待，但发生循环等待未必死锁）

##### 死锁的处理策略

1. 死锁预防：破坏4个必要条件的一个或几个
2. 死锁避免：银行家算法
3. 死锁检测、死锁解除：允许死锁发生，但操作系统会负责检测死锁的发生，然后采取某种措施解除死锁（资源剥夺法、撤销进程法、进程回退法）

### 3. 内存管理▲

#### 物理内存和虚拟内存

> https://www.cnblogs.com/liangping/p/12601281.html

- 物理内存：实际内存条（RAM）中的内存
- 虚拟内存：操作系统为了对进程地址空间进行管理设计的逻辑意义上的内存空间，让应用程序认为它拥有连续可用的内存，为了<u>提高物理内存的利用率</u>。早期的程序直接运行在物理内存上，存在地址空间不隔离、内存利用率低等问题；虚拟内存可以<u>避免直接访问物理内存，保护操作系统</u>。（指针其实是逻辑内存空间中的地址）

- 驻留内存：被映射到进程虚拟内存的物理内存。进程的驻留内存就是进程实际占用的物理内存。虚拟内存大并不意味着占用的物理内存大（比如，A1、A2、A3和A4都是A的驻留内存）
- 共享内存：程序会依赖于很多外部的动态库(.so)，在内存中仅仅保存一份（A4/B3这部分）

linux的top命令能看出进程虚拟空间的总大小（VIRT）、驻留内存/占用的物理内存（RES）以及和其他进程共享的内存（SHR）



![](https://raw.githubusercontent.com/liangpinglk/note/master/picture/memory/virt_phy_memory.png)



#### 物理地址 虚拟地址 逻辑地址 线性地址

> https://www.cnblogs.com/Doing-what-I-love/p/5533075.html

- 物理地址：与物理内存对应的地址
- 虚拟地址：进程在虚拟空间中的地址
- 逻辑地址：程序产生的与段相关的偏移地址：段标识+段内偏移量
- 线性地址：段基址+段内偏移地址就是线性地址。如果启用了分页机制，那么线性地址可以再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址

MMU寄存器负责将虚拟地址转化为物理地址

页映射表：将程序运行过程中需要访问的一段虚拟内存空间通过页映射表映射到一段物理内存空间上。内核会为系统中每一个进程维护一份相互独立的页映射表。



#### 虚拟内存基本概念

![image-20200717124915991](C:\Users\YRR\AppData\Roaming\Typora\typora-user-images\image-20200717124915991.png)

#### 页式 vs 段式 vs 段页式

非连续内存分配

- 分页存储管理
  将各进程的虚拟空间划分为若干个长度相等的页。页的大小固定且由系统决定（系统中只能有一种大小的页面）把内存空间按页的大小划分为片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表，并用相应的硬件地址转换机构来解决离散地址变换问题。页式管理采用请求调页和预调页技术来实现内外存存储器的统一管理。为每个进程建立一张页表
  优：没有外碎片，每个内存碎片不超过页的大小

- 分段存储管理

  进程地址空间：按照程序自身的逻辑关系划分为若干个段，每段从0开始编址

  内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，长度大小不固定，但段之间可以不相邻

  分段系统的逻辑地址结构：段号（段名）+段内地址（段内偏移量），段号的位数决定了每个进程最多可以分几个段，段内地址位数决定了每个段的最大长度

  - 与分页最大的区别：离散分配时所分配地址空间的基本单位不同

- 段页式管理

  将地址空间按照程序自身的逻辑关系划分为若干段，再将各段分为大小相等的页面

  将内存空间分为与页面大小相等的一个个内存块，系统以块为单位为进程分配内存

  逻辑地址结构：（段号，页号，页内偏移量）

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507154258573.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507160703773.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

交换技术：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已经具备运行条件的进程换入内存（许多进程运行时经常发生缺页，说明内存紧张，需要换出一些进程）

#### 动态内存分配算法

- 首次适应算法：空闲分区以**地址递增**的次序排列，每次分配内存时**从头查找**得到第一个满足要求的空闲分区
- 最佳适应算法：空闲分区按**容量递增**排序，每次顺序查找第一个满足要求的空闲分区
- 最坏适应算法：空闲分区按**容量递减**排序，每次顺序查找第一个满足要求的空闲分区
- 邻近适应算法：空闲分区以**地址递增**的次序排列，每次分配内存时**从上次查询结束的位置**开始找



#### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

1. **最佳置换算法（OPT）**从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。于所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。

2. **先进先出置换算法（FIFO）**：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。（可能出现Belady 异常）

3. **最近最久未使用（LRU）算法**：利用局部性原理，选择在最近一段时间内最久不用的页面予以淘汰。 

   [146. LRU缓存机制](https://leetcode-cn.com/problems/lru-cache/) unordered_map + list

4. **时钟(CLOCK)置换算法**：当某一页首次装入主存时，该帧的使用位设置为1；当该页随后再被访问到时，他的使用位也被置为1.对于液体换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被指为0的帧，每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1，则指针在缓冲区中完整的循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。

5. **最不经常使用(LFU)算法**：[460. LFU缓存](https://leetcode-cn.com/problems/lfu-cache/)



#### linux命令

- 目录操作：mkdir rmdir cd
- 文件操作：ls echo cat rm cp mv
- 文件内容操作：grep sed awk
- 网络命令：ipconfig ps netstat





## 计算机网络

TCP/IP网络层次模型



### 应用层（HTTP、HTTPS、DNS）

> https://blog.csdn.net/qq_36894974/article/details/103930478?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase



#### 浏览器输入一个URL到页面加载的过程▲

> [从输入URL到页面加载发生了什么](https://segmentfault.com/a/1190000006879700)

1. DNS解析
2. 三次握手建立TCP连接
3. 客户端发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束

#### DNS解析（采用UDP）

首先在浏览器dns缓存中寻找是否有解析的ip地址，如果没有，则在本机hosts文件中找；如果还没有，则请求本地域名系统解析域名，如果本地域名系统的缓存中没有相应的ip地址，那么本地域名系统则会依次向根域名系统、顶级域名系统、次域名系统进行逐级迭代查询，最后本地域名系统会将URL对应的IP地址返回给主机。

#### HTTP 包结构

HTTP是无状态的协议
- 定义：用于HTTP协议交互的信息被称为HTTP报文，HTTP报文本身是由多行数据构成的字符串文本。（HTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。）
- 结构（HTTP报文由**报文首部**和**报文主体**构成，中间由一个空行(CRLF)分隔。）
    1. 报文首部：是客户端或服务器端需处理的响应或请求的内容及属性，可以传递额外的重要信息。
    2. 空行（回车+换行 CR+LF）
    3. 报文主体：包含应被发送的数据。通常不一定由报文主体。
- 类别：
    1. **请求报文**：客户端的HTTP报文
        - 请求行：请求方法 URI资源位置 HTTP协议版本，用空格分开
        `GET /index.html HTTP/1.1`
        - 请求头部：描述请求正文，用于说明请求源、连接类型及Cookie信息等
        - 空行
        - 请求正文：一般用于存放POST请求类型的请求正文，如`username=jack&sex=man`
        
        ![image-20200809130154118](C:\Users\YRR\AppData\Roaming\Typora\typora-user-images\image-20200809130154118.png)
        
        ![image-20200809130205957](C:\Users\YRR\AppData\Roaming\Typora\typora-user-images\image-20200809130205957.png)
        
    2. **响应报文**：服务器端的HTTP报文
        - 状态行：HTTP版本 响应返回状态码 响应描述
        
    - 响应头部：返回服务器的基本信息，及Cookie值等
      
    - 空行
      
        - 响应体：为请求需要得到的具体数据，可以是任何类型，网页浏览一般返回html文件内容
          
        
          ![image-20200809130218521](C:\Users\YRR\AppData\Roaming\Typora\typora-user-images\image-20200809130218521.png)

#### HTTP 请求方法▲

GET：从服务器端获取数据（幂等的）

HEAD：类似于 GET 请求，用于获取报头，不返回消息正文。用于检查资源/超链接的有效性

POST：向服务器端上传数据

PUT：从客户端向服务器端传送的数据取代指定文档的内容（幂等的）

DELETE：请求服务器删除指定页面

OPTIONS：

##### GET vs POST▲

- GET是从服务器上获取数据（即下载），POST是向服务器传送数据（即上传）

- GET参数通过URL传递，POST放在Request body中 （GET传递的请求数据按照key-value的方式放在URL后面，在网址中可以直接看到，使用?分割URL和传输数据，传输的参数之间以&相连，如：login.action?name=user&password=123,安全性差。POST会把请求的参数放到请求正文中以&分隔各个字段，URL中不会额外附带参数，安全性高。)

- 发送数据大小：GET有限制，POST无。(不同浏览器对请求的处理方式不同，大多数浏览器会限制URL的长度)

- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制

- GET产生一个TCP数据包；POST产生两个TCP数据包。

  对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

- <u>GET是安全的和幂等的</u>（安全的：操作用于获取信息而非修改信息，幂等的：对同一 URL 的多个请求应该返回同样的结果）





#### http1.0 vs http1.1 vs http2.0

- http1.0：短连接，连接无法复用。浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接。

- http1.1：

  1. 长连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。`Connection=Keep-Alive`
  2. Host头：HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名，现在有了虚拟主机技术，一台服务器上可以多个虚拟主机，有了host字段可以将请求发给同一台服务器上的不同站点
  3. 支持断点续传 `range:bytes`,可以要求服务器从文件的某个字节处开始传送

- http2.0：

  1. 二进制分帧层：http1.0，1.1的头信息是基于文本的ASCII码，而http2.0的报头和报文主体都是二进制码

     http2.0把HTTP通信的基本单位缩小为帧，把首部信息放到header帧，主体信息放到data帧

  2. 多路复用：在一个连接里，客户端和浏览器都可以同时发送多个请求和响应，而不用按照顺序一一对应，这样避免了“队头堵塞”并行地在同一个 TCP 连接上双向交换消息（http1.1中浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞）。

  3. header压缩：header带有大量的信息，且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。

  4. **服务端推送**（server push），把客户端所需要的资源伴随着index.html一起发送到客户端。比如客户端的网页有一个sytle.css的请求，在客户端收到sytle.css数据的同时，服务端会将sytle.js的文件推送给客户端，当客户端再次尝试获取sytle.js时就可以直接从缓存中获取到，不用再发请求了

##### 长连接 短连接

- 短连接：假设有一个网页，里面包含好多图片，还包含好多**外部的**CSS 文件和 JS 文件。在“短连接”的模式下，浏览器会先发起一个 TCP 连接，拿到该网页的 HTML 源代码（拿到 HTML 之后，这个 TCP 连接就关闭了）。然后，浏览器开始分析这个网页的源码，知道这个页面包含很多外部资源（图片、CSS、JS）。然后针对**每一个**外部资源，再分别发起一个个 TCP 连接，把这些文件获取到本地（同样的，每抓取一个外部资源后，相应的 TCP 就断开）

  HTTP1.0默认使用短连接

- 长连接：浏览器也会先发起一个 TCP 连接去抓取页面。但是抓取页面之后，该 TCP 连接并不会立即关闭，而是暂时先保持着（所谓的“Keep-Alive”）。然后浏览器分析 HTML 源码之后，发现有很多外部资源，就用刚才那个 TCP 连接去抓取此页面的外部资源。

  HTTP1.1默认采用长连接

#### Cookie vs Session

http无状态。既然服务器没有记忆能力，它就无法支持需要连续多个步骤的`事务`操作。每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量。由此出现了 `Cookie` 技术。

- cookie数据存放在客户的浏览器上，session数据放在服务器上（在服务端保存的用来跟踪用户的状态的数据结构）
- Cookie 支持跨域名访问，例如，将 domain 属性设置为“.biaodianfu.com”，则以“.biaodianfu.com”为后缀的一切域名均能够访问该Cookie。跨域名Cookie如今被普遍用在网络中，例如，Google、Baidu、Sina等。
- cookie安全性一般，可用过分析存放在本地的cookie进行欺骗。重要交互信息比如权限等就要放在Session中，一般的信息记录放Cookie就好了。
- 单个Cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个Cookie
- 每次HTTP请求时，客户端都会发送相应的Cookie信息到服务端。
- session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。
- 用户验证这种场合一般会用 Session。因此，维持一个会话的核心就是客户端的唯一标识，即Session ID。

在浏览器关闭后这次的Session就消失了，下次打开就不再拥有这个Session。其实并不是Session消失了，而是Session ID变了，服务器端可能还是存着你上次的Session ID及其Session 信息，只是他们是无主状态，也许一段时间后会被删除。

目前大多数的应用都是用Cookie 实现Session跟踪的。第一次创建Session时，服务端会通过在HTTP协议中反馈到客户端，需要在 Cookie 中记录一个Session ID，以便今后每次请求时都可分辨你是谁。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？建议使用URL重写技术进行会话跟踪，即每次HTTP交互，URL后面都被附加上诸如 sid=xxxxx 的参数，以便服务端依此识别用户。

#### HTTP 状态码▲
状态码是用来告知客户端服务器端处理请求的结果。

状态码是由3位数组成，第一个数字定义了响应的类别，且有五种可能取值:

- 1xx：通知–表示请求已接收，继续处理。
- 2xx：成功–表示请求已被成功接收、理解、接受。
- 3xx：重定向–要完成请求必须进行更进一步的操作。
- 4xx：客户端错误–请求有语法错误或请求无法实现。
- 5xx：服务器端错误–服务器未能实现合法的请求。

平时遇到比较常见的状态码有:200（客户请求成功），201（服务器按照客户端的请求创建了一个新资源）, 204, 301（请求永久重定向，该状态码表示请求的资源已经被分配了新的URL，以后应该使用资源现在指定的URL）, 302（请求临时重定向）, 304, 400, 401, 403（forbidden表明请求访问的资源被拒绝了）, 404, 422, 500, 503 。



#### http vs https▲

- http(Hypertext transfer protocol)超文本传输协议，通过浏览器和服务器进行数据交互，进行超文本（文本、图片、视频等）传输的规定。也就是说，http协议规定了超文本传输所要遵守的规则。

- https：在http(超文本传输协议)基础上提出的一种安全的http协议，因此可以称为安全的超文本传输协议。http协议直接放置在TCP协议之上，而https提出在http和TCP中间加上一层加密层。从发送端看，这一层负责把http的内容加密后送到下层的TCP，从接收方看，这一层负责将TCP送来的数据解密还原成http的内容。

  1、https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。
  2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
  3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
  4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

#### https安全
- http是明文传输，而网络请求中间有很多的服务器路由器的转发，之间的结点都可能监听、伪装、篡改信息。
    - 监听：通信内容被获取。数据在客户端与服务端通信过程中，任何一点都可能被劫持（eg.发送了银行卡号和密码，中间人劫取数据就能看到卡号和密码）
    - 伪装：冒充他人身份参与通信。http通信时，无法保证通信双方是合法的，通信方可能是伪装的（eg.修改用户的请求头URL，导致用户的请求被劫持到另一个网址，导致用户的请求到不了真正的服务器）
    - 篡改：通信内容被修改。接收方不知道数据已经被中间人篡改（eg. 中间人将广告链接嵌入到服务器发送给用户的http报文里，导致用户界面出现不良链接）
    
- 而https在http加了一个安全协议(SSL/TSL<Transport Layer Security,传输层安全协议>)，保证传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。
  
    通过数据加密、校验数据完整性和身份认证三种机制来保障安全
    
    - 防监听：数据加密，监听到的是密文
    - 防伪装：通信双方携带证书（相当于身份证），有证书认为是合法的，无证书非法（证书由第三方颁布，难以伪造）
    - 防篡改：https对数据做了摘要，篡改数据会被发现
#### 加密算法

- 对称加密：
    - 加密解密采用同样的密钥
    - 计算量小、加密速度快、效率高
    - 常见算法由：AES、DES
- 非对称加密：使用了一对密钥，公钥和私钥。（RSA）
  公钥是公开的，任何人/客户端都可以获取，客户端使用公钥加密数据，服务端用私钥解密数据
- 摘要算法：经过算法运算后生成固定长度的数据，是不可逆的过程。主要用于验证消息完整性（每个数据生成的MD5值不同）、安全访问认证（账号登录的密码）、数字签名（结合非对称加密算法和CA证书）
  - MD5：将任意长度的字符串转变为128位的大整数，是不可逆的字符串变换算法（无法将一个MD5的值转变回原始的字符串），速度快
- SHA1:160位，强度更高
#### https整个加密过程▲

> http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html

SSL： 在传输层。在TCP协议之上，应用层之下运作，是用来传输敏感信息的。使用SSL连接的URL地址以https开头，而不是http。
优点： 非对称加密只使用了一次，后续所有的通信消息都是用对称加密，效率比非对称加密高。

- 服务器端需要认证的通信过程
    1. 客户端发起 HTTPS 请求，包含(a)一个客户端生成的随机数(Client random) (b)客户端支持的加密协议及(c)支持的协议版本（SSL/TLS）
    
       客户端(如浏览器)对一些加解密算法的支持程度不一样，但是在TLS协议传输过程中必须使用同一套加解密算法才能保证数据能够正常的加解密。在TLS握手阶段，客户端首先要告知服务端，自己支持哪些加密算法，所以客户端需要将本地支持的加密套件(Cipher Suite)的列表传送给服务端。
    
    2. 服务端返回证书，包含(a)服务器证书<包含公钥>(b)一个服务器端生成的随机数(Server random)(c)确认使用的加密通信协议版本(d)确认使用的加密方法
    
    3. 客户端使用根证书验证证书合法性，验证通过后，客户端生成一个新的随机数(Premaster secret)，通过证书中的公钥对其进行加密，发送到服务端
    
       浏览器判断证书发布者CA是否属于系统中内置的受信任的证书发布机构，校验证书的合法性->取出公钥对证书里的签名进行解密->使用相同的hash算法计算证书的hash值，并将计算得到的hash值与证书中的签名对比
    
    4. 服务端使用私钥解密得到随机数(Premaster secret)
    
    5. 客户端和服务器端使用前面的三个随机数，生成对话密钥(session key)，握手之后的对话使用对话密钥加密（对称加密）对称密钥解密数据
    
    6. SSL加密建立（之后的数据交互通过对称加密算法进行加解密）

- 客户端需要认证的通信过程
支付宝、银行客户端等金融应用需要在客户端安装证书

HTTPS= 数据加密+网站认证+完整性验证+HTTP

对称加密的缺点：

（1）不同的客户端、服务器数量庞大，所以双方都需要维护大量的密钥，维护成本很高

（2）因每个客户端、服务器的安全级别不同，密钥极易泄露



>  [拓]12306刚上线的时候，有证书，为什么还提示证书不可信呢  [字客1]

### 传输层（TCP、UDP）

#### 1. TCP vs UDP

- TCP是面向连接的、可靠的字节流传输协议（包含建立连接、数据传输、断开连接过程）；UDP是无连接、不可靠的数据发送协议（传输时连接的建立与断开、传输可靠性均有上层应用程序处理）
- TCP是一对一的传输；UDP支持一对一、一对多、多对一、多对多的交互通信
- TCP是面向字节流的（把应用层传来的报文看成字节流，将字节流拆分成大小不等的数据块，并添加TCP首部，首部是20个字节）；UDP是面向报文的，不对应用层传来的报文拆分或合并，只是添加了UDP首部（8个字节）
- TCP保证传输可靠性的方式：确认应答、超时重传、数据有序、流量控制、拥塞控制；UDP仅提供最基础的数据传输能力，发送方根据对方的IP地址发送数据包，但不保证接受发送包的质量，数据无序还容易丢包。虽然UDP协议不稳定但是在即时通讯（QQ聊天、在线视频、网络语音电话）的场景下，可以允许偶尔的断续，但是这种协议开销小、简单、传输速度快。
- TCP对应应用层的协议主要有SMTP(25)、TELNET(23)、HTTP(80)、FTP(21,20)等；UDP对应应用层的协议主要有DNS(53)、TFTP(69)、DHCP、SNMP、NFS等。

#### 2. TCP

##### TCP可靠传输▲

TCP保证传输可靠性的方式：确认应答、超时重传、数据有序、流量控制、拥塞控制

1. 确认应答：接收方收到报文会进行确认。
2. 超时重传：TCP发出一个分组后，将启动一个定时器，等待接收端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 
3. 数据有序：每个数据包中都有序列号，接收端会将接收到的数据包根据序列号进行排序，并且去掉重复序列号的数据。
4. 流量控制：接收方采用滑动窗口控制发送方的发送量，可以防止接收方可用的数据缓冲空间溢出。滑动窗口会指明接收能够接收的最大数据量【接收方能来得及接收】 
5. 拥塞控制：如果网络拥塞，分组将会丢失，此时发送方会重传，导致网络拥塞程度更高。采用“慢启动”、“拥塞避免”、“快速重传 ”、“快速恢复”4种算法控制发送方的速率。【降低整个网络的拥塞程度】
6. 校验和：检验首部和数据

##### 拥塞控制▲

> [TCP的拥塞控制（详解）](https://blog.csdn.net/qq_41431406/article/details/97926927)

为了进行拥塞控制，TCP发送方要维持一个**拥塞窗口**(cwnd)的状态变量，其大小取决于网络的拥塞程度，并动态变化。发送方让自己的发送窗口=min(拥塞窗口,接收窗口)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731165743903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

- 慢开始：当主机开始发送数据时，如果立即把大量数据字节注入到网络，可能会引起网络阻塞。先探测以下，由小到大逐渐增大发送窗口<拥塞窗口数值cwnd>，cwnd初值为1，每经过一个传播轮次（RTT时间），cwnd加倍（1,2,4,8,16,..呈指数增长）
- 拥塞避免：让拥塞窗口cwnd缓慢增大，每经过一个往返时间RTT就把发送方的cwnd+1（线性增长）
- 快重传：让发送方尽快进行重传，而不是等超时重传计时器超时再重传
- 快恢复：发送方一旦收到3个重复确认，就知道现在只是丢失了个别报文段，于是不启动慢开始算法，而执行快恢复算法。
  
- 发送方将慢开始门限ssthresh以及cwnd都设为当前窗口的一半，并开始执行拥塞避免算法



慢开始门限ssthresh

- 当cwnd<ssthresh：采用慢开始算法
- 当cwnd>ssthresh：采用阻塞避免算法
- 当发送方超时重传，则误以为网络发送拥塞，将ssthresh设为发生拥塞时cwnd的一半，并将cwnd重置为1，重新采用慢开始算法

##### 拥塞控制 vs 流量控制

- 流量控制：**控制发送方发送速率，保证接收方来得及接收**。TCP利用滑动窗口实现流量控制。（接收方发送的ACK报文中的窗口字段可以用来控制发送方窗口大小）<点对点通信量的控制，是端到端的问题>
- 拥塞控制：**降低整个网络的拥塞程度，防止过多的数据注入到网络中，使网络中的路由器或链路不至于过载。**<是全局性过程，涉及所有主机、路由器以及于降低网络传输性能有关的所有因素>（拥塞：对网络中某一资源的需求超过该资源所能提供的可用部分，网络的性能可能就要变坏）

##### 三次握手（建立连接）▲

刚开始客户端处于closed状态，服务端处于listen状态

1. 第一次握手：客户端给服务器端发送一个**SYN报文**，并指明客户端的初始化序列号seq=x（SYN=1,ACK=0,seq=x）。此时客户端处于SYN_Send<同步已发送>状态。
   - SYN报文段不能携带数据，但需要消耗一个序号
2. 第二次握手：服务器收到客户端的SYN报文后，发送**SYN+ACK**报文，会以自己的SYN报文作为应答，同时也指定了自己的初始化序列号seq=y（SYN=1,ACK=1,seq=y,ack=x+1），同时会把客户端的序列号x+1作为确认号ack，表示自己已经收到了客户端的SYN，此时服务器处于SYN_REVD<同步收到>状态
3. 第三次握手：客户端收到SYN+ACK报文后，会发送一个**ACK报文**（ack=y+1），表示已经收到了服务器端的SYN报文，此时客户端处于established<已建立连接>状态（TCP连接成功）
   - ACK报文段可以携带数据，如果不携带数据则不消耗序号
4. 服务器端收到ACK报文后，也处于established状态，此时双方建立起了连接，客户端和服务器端可以正式开始传送数据

SYN只有在TCPTCP 建立连接时才为1，握手完成后为0

##### 四次挥手（终止连接）▲

1. 第一次挥手：客户端发送一个**FIN报文**，报文中会指定一个序列号（seq=u,FIN=1,u=前面已经传来的数据的最后一个字节的序号+1）。此时客户端处于FIN_WAIT1状态。
   - FIN报文段即使不携带数据，也要消耗一个序号
2. 第二次挥手：服务器端收到FIN报文后，会发送**ACK报文**，且把客户端的序列号+1作为ACK报文，表明已经收到客户端的报文了（seq=v,ACK=1,ack=u+1），此时服务器端处于CLOSE_WAIT状态。
   - TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时处于半关闭状态（客户端已经没有要发送的数据了，但服务器若发送数据，客户端仍要接收。整个状态需要持续一段时间，也就是整个CLOSE_WAIT持续的时间）
3. 客户端收到服务器的ACK报文后，就进入FIN_WAIT2状态，等待服务器端发送FIN报文（在这之前还需要接受服务器端发送的最后的数据）
4. 第三次挥手：如果服务器端将最后的数据发送完毕后，也想断开连接了，就和客户端的第一次挥手一样，发出**FIN报文**，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为w（FIN=1,seq=w,ack=u+1）。此时服务器端处于LAST_ACK状态等待客户端的确认。
5. 第四次挥手：客户端收到FIN报文后，同样发送一个**ACK报文**作为应答（ACK=1,seq=u+1,ack=w+1），此时客户端处于TIME_WAIT状态。【注】此时TCP连接还未释放，需要经过2xMSL（最长报文段寿命）的时间后，确保服务器端收到自己的ACK报文后才进入CLOSED状态。（seq=x,ack=y）
6. 服务器端收到ACK报文后，就立即关闭连接，处于CLOSED状态。（可以看出，服务器结束TCP连接的时间比客户端早一些）

##### 为什么TCP不是两次握手or四次握手？ 

> [TCP的三次握手与四次挥手理解及面试题（很全面）](https://blog.csdn.net/qq_38950316/article/details/81087809?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)

**为什么不是两次握手？**

- **防止失效的连接请求报文段被服务端接收而产生错误。**<失效的连接请求：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时上一个连接请求就是**失效的**>
  若建立连接只进行两次握手，那客户端没有太大变化，仍需要获得服务器应答后才进入establish状态，而服务器段在收到连接请求后就进入establish状态。若此时网络拥塞，客户端发送的连接请求迟迟到不了服务器，客户端就会超时重发请求，如果服务端正确接收并确认应答，双方便开始通信，通信结束后会释放连接。此时如果那个失效的连接请求到达服务端，由于只有两次握手，服务端收到请求后进入establish状态，会等待发送数据或主动发送数据。但此时客户端早已进入closed状态，那么服务器端将会一直等下去，会浪费服务端的连接资源。
- 双方都需要确认对方收到了自己发送的序列号

**为什么是四次挥手?**

- 建立连接时，服务器端可以直接发送SYN+ACK报文
- 关闭连接时，服务器端会先回复一个ACK报文，但可能还需要发送一些数据后再发送FIN报文，表示同意关闭连接。因此，ACK报文和FIN报文往往是分开发送的。

TCP 三次握手和四次挥手。TIME_WAIT 为什么是 2MSL 而不是 1MSL 或者 3MSL？

##### TIME_WAIT 

2MSL就是一个发送和一个回复所需的最大时间。

TIME_WAIT状态就是用来重发可能丢失的ACK报文

- 保证客户端发送的最后一个ACK报文能达到服务器。（如果网络不可靠，可能会丢失最后的ACK报文。如果在2MSL内客户端再次收到FIN，那么会重发并再次等待2MSL。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。）
- 防止类似三次握手中提到的“已失效的连接请求报文段”出现。可能会在相同的IP地址和端口建立新的连接，为了防止新连接中出现旧连接的请求报文。客户端发送完最后的ACK报文后，在2MSL时间内，可以使本连接持续时间内所产生的所有报文段从网络中消失。

##### TCP keep alive

解决已经建立了连接，但是客户端突然出现故障的情况。为防止资源浪费，TCP还设有一个保活计时器。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

#### socket

> https://blog.csdn.net/codedoctor/article/details/87978716

![image](https://images.cnblogs.com/cnblogs_com/goodcandle/socket3.jpg)

socket：创建一个socket并返回socket描述符（与普通文件打开类似）

bind：服务器在启动时会绑定一个众所周知的地址（IP+端口号）用于提供服务。由于客户端不用指定，在connect时由系统随机生成

accept：服务端接收到请求会调用accept表示同意请求





#### ping

ping 检查两个主机之间的连通性，利用网络上机器IP地址的唯一性，给目标IP地址发送一个ICMP数据包，再要求对方返回一个同样大小的数据包来确定两台网络机器的联通情况和联通时延

可以直接ping主机域名

TTL（Time To Live） 数据包的生存时间。数据报经过每个路由器时TTL的值都会减1，所以通过TTL的最终值可以计算出数据报从本地到目的主机所经过的路由器的个数。经过路由器个数=$2^a$ -TTL最终值（其中$2^a$必须大于等于TTL最终值且最后计算出的路由器个数小于等于TTL最终值）

windows 10 默认是128

```
ping 127.0.0.1 
ping www.baidu.com
```

#### localhost

localhost其实是域名，一般windows系统默认将localhost指向127.0.0.1，但是**localhost**并不等于`127.0.0.1`，**localhost**指向的**IP地址**是可以配置的



## C++

### C++特性 

- **封装**：把客观事物封装成抽象的类；将类的实现与接口分离，隐藏了类的实现细节，通过设置访问权限，保护类的成员不被随意访问【隐藏实现细节，代码模块化】
- **继承**：可以扩展已存在的类，让子类获得父类的属性【功能复用】
- **多态**：用父类的指针或引用统一操作各种子类对象。一个动作在不同情况下有不同的表现【向后兼容，可扩充】

```cpp
Animal *v[3]={&dog,&cat,&duck};
for(int i = 0; i<3; i++){
    v[i]->sound();
}
```

#### 多态

C++多态分为静态多态和动态多态

1. 静态多态<编译期完成>：函数重载（重载多态：函数重载、运算符重载）、泛型编程（参数多态：类模板、函数模板）
2. 动态多态<运行期完成>：虚函数，父类指针或引用可以根据所指的对象决定具体调用哪个类的虚函数

#### 重载 vs 重写（覆盖）

- 重载（overload）：允许存在多个**同名函数**，而这些函数的**参数表不同**（参数类型、参数数量、或两者）
  - 编译器根据函数不同的参数表，对同名函数的名称做修饰，然后这些同名函数就成了不同的函数（至少对于编译器来说是这样的）
  - 对于这两个函数的调用，在编译期就已经确定了，是静态的。也就是说，它们的地址在**编译期**就绑定了（早绑定）

- 重写（override）：子类重新定义父类虚函数的方法（和多态真正相关）
  - 当子类重新定义了父类的虚函数后，父类指针根据赋给它的不同的子类指针，动态的调用属于子类的该函数，这样的函数调用在编译期间是无法确定的（调用的子类的虚函数的地址无法给出）。因此，这样的函数地址是在**运行期**绑定的（晚绑定）。



#### 避免多继承二义性的办法

二义性：派生类与基类中存在名字相的数据或函数

解决方法：

1. 使用域运算符。在引用数据成员/成员函数时指明其作用域（类名::数据名）
2. 同名覆盖原则
3. 虚继承：让继承间接共同基类时只保留一份成员

```cpp
class A{};
class B:virtual A{};
class C:virtual A{};
class D:public B,public C{};
```

虚继承

父类对象中存在一个指向其虚拟父类子对象的一个指针（虚父指针）

#### 为什么可以由子类对象new一个父类对象，反之不行 [字客1]  

- 子类继承于父类，它含有父类的部分（除了父类私有属性和私有方法），又做了扩充。如果子类对象赋值给父类对象，则使用该对象只能访问子类的父类部分（因为子类含有父类的部分，所以不会有问题）
- 如果用子类指针指向父类的话,一旦访问子类特有的方法函数或者成员变量(父类是没有的),就会出现非法访问。因为被子类指针指向的由父类创建的对象,根本没有要访问的那些内容,那些是子类特有的,只有用子类初始化对象时才会有.（当子类指向父类的指针,因为内存空间比父类长,访问的话会导致内存溢出,所以不允许子类的指针指向父类）


### static

- 全局变量：本身是静态存储方式，作用域是整个源程序（可被其他源文件使用）
  static全局变量：静态存储，只初始化一次，作用域是变量所在的源文件

- static局部变量：只初始化一次，下一次依据上一次的结果

- 普通函数：在每个被调用中维持一份复制品
  static函数：作用域仅在本文件，需要在本文件中声明、定义，在内存中只有一份

### const

#### const关键字作用[字客1]

编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。

1. 修饰变量，说明该变量不可以被改变，编译器可以对其进行数据静态类型安全检查；
2. 修饰指针，分为**底层const**（指向常量的指针）和**顶层const**（常量指针，指针本身是常量）；

```cpp
//由近到远读
int a = 1;
const int* p1 = &a; //底层const：p1是个指针，指向int型对象，该对象是个常量
int* const p2 = &a; //顶层const：p2是个常量，p2是个指针，指向int型对象
```

3. 修饰引用，指向常量的引用（reference to const），用于形参类型，将值传递改为const &传递（不需要产生临时对象），即避免了拷贝，又避免了函数对值的修改；
4. 修饰函数的返回值，如果给“指针传递”的函数返回值加const，则返回值不能被直接修改，且只能被赋给加const修饰的同类指针
5. 修饰成员函数，说明该成员函数内不能修改成员变量，但可以读取数据成员。（声明、定义的时候都必须在参数列表后指定const）
6. 修饰数据成员：在某个对象生存期内是常量，而对于整个类而言是可变的，因为类可以创建多个对象，不同对象的const数据成员的值可以不同。（不能在类声明中初始化const数据成员，只能在类构造函数的初始化表中进行）
   常量对象及常量对象的引用/指针都只能调用常量成员函数

```cpp
class A{
    const int SIZE; //正确
    //const int SIZE=100; //错误，企图在类声明中初始化const数据成员
    //int array[SIZE]; //错误，SIZE未知
public:
    A(int size);
};
A::A(int size):SIZE(size)//构造函数的初始化表
{
}
```

【拓】建立在整个类中都恒定的常量：利用类中的枚举常量
枚举常量不会占用对象的存储空间，它们在编译时被全部求值。枚举常量的缺点是：它的隐含数据类型是整数，其最大值有限，且不能表示浮点数（如PI=3.14159）

> [相关链接](https://blog.csdn.net/love_gaohz/article/details/7567856?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)


1. 成员变量

- static 数据成员：类的全局变量，会被类的所有对象共享，包括派生类的对象
  必须在类外初始化，不同通过构造函数初始化，类外初始化时不加static修饰。(初始化格式：`int Base:var=10`)
- const 数据成员：限定变量不能被修改

2. 成员函数

- static 成员函数：所有对象共享该函数，不含this指针。static成员函数不能直接引用类中的非静态成员、const成员、const static成员，可以引用类中的static成员。可以获取类中的static成员、const static成员的值
- const成员函数：限定成员函数不能修改对象的普通数据成员（除了mutable、static数据成员），会在函数中添加一个隐式的参数this指针（这个指针总指向某个特定对象）`int GetCount(void) const;`


#### 类里面的变量可以既是const又是static

可以，表示类的静态常量<必须在定义的时候初始化>（如果是public，可以直接用类获取；如果是private，可以利用成员函数获取）

- static数据成员：必须在**类外**进行初始化，而不能在构造函数内进行初始化
- const数据成员：可以在**定义的时候初始化**，也可以通过**构造函数的初始化列表**进行初始化（但是不能在构造函数的函数体内初始化）
- const static 数据成员：可以在类内初始化`const static int m_const_static=1; `，也可以在类外初始化`const int Base::m_const_static(1);`  `const int Base::m_const_static=1;`。

但是，**类的成员函数不能既是const又是static**

C++编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数`const this` 。但当一个成员为static的时候，该函数是没有this指针的。也就是说此时const的用法和static是冲突的。

static的作用是表示该函数只作用在类型的静态变量上，与类的实例没有关系；
而const的作用是确保函数不能修改类的实例的状态，与类型的静态变量没有关系。


this的类型是指向类类型非常量版本的常量指针，不能把它绑定到一个常量对象上。
this的类型是`Base *const`（指向Base类对象的常量指针），常量成员函数的把this声明成了`const Base *const`（指向常量对象的常量指针）

#### `const char *p; char const *p; char * const p;`三个的区别

(从右往左读，`*` 读成 pointer to) 

1. `const char *p;`: p is a pointer to const char【底层const】
2. `char const *p;`: 同1，p is a pointer to const char【底层const】
3. `char * const p;`: p is a const pointer to char【顶层const】

#### 宏与const常量的区别

1. 编译器处理不同
   - 宏：是个“编译时”概念，在预处理阶段进行的（在编译时把所有用到宏定义值的地方用宏定义常量替换），生命周期结束于编译期
   - const：是个“运行时”概念，在程序运行时使用，可看作一个只读变量
2. 存储方式不同
   - 宏：直接替换，不为它分配内存
   - const：需要进行内存分配（static const 分配在全局变量区，局部变量分配在栈区）
3. 类型和安全检查不同
   - 宏：只进行文本替换（不计算、不进行表达式求解），没有数据类型，在编译时不会进行类型安全检查，可能产生边际效应等错误
   - const有具体的数据类型，在编译时会检查错误

【拓】
宏的缺点：

1. 容易出错，预处理器在拷贝代码时常常产生意想不到的边际效应
2. 宏不可调试，而内联函数可调试
3. 宏无法操作类的私有数据成员

### sizeof

#### C++中不能被重载的运算符有哪些？

不能重载的运算符只有5个：

（1）. （成员访问运算符）。

（2）.* （成员指du针访问运算符）。

（3）∷（域运算符）。

（4）sizeof（长度运算符）。

（5）?: （条件运算符）。

#### 没有数据成员的类所占字节数

> [c++中各类型数据所占字节数（二）](https://www.cnblogs.com/zhangxuan/p/10751126.html)

空的类是会占用内存空间的，而且大小是1个字节，原因是C++要求每个实例在内存中都有独一无二的地址。

1. 类内部的数据成员：
   - 普通数据成员：是要占用内存的，但是要注意对齐原则(这点和struct类型很相似)
   - 静态数据成员：不占用内存，静态变量存放在全局变量区。
2. 类内部的成员函数：
   - 普通函数：不占用内存。
   - 虚函数：要占用4个字节，用来指定虚函数的虚拟函数表的入口地址。所以一个类的虚函数所占用的地址是不变的，和虚函数的个数是没有关系的。
3. 父类与子类：
   - 子类的大小是本身成员变量的大小加上父类的大小
   - 父类子类共享一个虚函数指针

[【C++拾遗】 从内存布局看C++虚继承的实现原理](https://blog.csdn.net/xiejingfa/article/details/48028491) 
    

```cpp
//1.空类
class A{
};
//2.仅含静态数据成员和函数
class B{
private:
    static int n;
public:
    int func(){};
}
//3.含有不同字节长度的数据成员
struct C{
    int i;
    short j;
    char ch;
};
//4.虚函数
class D{
    virtual void funcD1(){};
    virtual void funcD2(){};
};
struct E{
    virtual void funcE();
};
// 5.多重继承
struct F: public D,public E{
};
// 6.虚继承???????????????????
class G{}；

int main(){
    A a;
    cout<<sizeof(a)<<endl;// 1  (空类的对象)
    cout<<sizeof(A)<<endl;// 1  (空类)
    cout<<sizeof(B)<<endl;// 1  (仅含静态数据成员和函数)
    cout<<sizeof(C)<<endl;// 8=4+2+1+1 偏移量：i:0, j:4, ch:6 （自动补齐）
    cout<<sizeof(D)<<endl;//4 (C++类中有虚函数的时候有一个指向虚函数的指针(vptr)，指针大小为4字节。无论多少个虚函数，只有这一个指针，4字节)
    cout<<sizeof(F)<<endl;//8=4+4 多重继承（父类D的虚函数指针和父类E的虚函数指针）
    
    return 0;
}
//5.多继承
class a{
    virtual void f();
};
class b{
    char ch;
};
class c:public a{
    virtual void fun() = 0;
};
class d:public a{
    char t;
    virtual void fun() = 0;
};
class f:public b,public c{};
int main()
{
    cout << "sizeof(a)=" << sizeof(a)<<endl;//4
    cout << "sizeof(b)=" << sizeof(b)<<endl;//1
    cout << "sizeof(c)=" << sizeof(c)<<endl;//4（父类子类共享一个虚函数指针）
    cout << "sizeof(d)=" << sizeof(d)<<endl;//8 （自动补齐 1个char类型数据，一个父类子类共享的虚函数指针）
    cout << "sizeof(d)=" << sizeof(f)<<endl;//8（为了提高实例在内存中的存取效率。类的大小往往被调整到系统的整数倍）
    return 0;
}
```

#### sizeof vs strlen

sizeof带有'\0'占位符
strlen只计算字符长度

```cpp
int main()
{
    char a[] = "aaa";
    char *p =a;
    cout<<"sizeof:"<<sizeof(p)<<endl; //4
    cout<<"strlen:"<<strlen(p)<<endl; //3
    return 0;
}
```

### 内联

> [inline](https://zhuanlan.zhihu.com/p/50812510)

- 内联机制用于优化规模较小、流程直接、频繁调用的函数。
- 定义在类内的成员函数/友元函数是自动inline的
- 在类外部定义的函数可加inline显式指定内联

对于任何类型的函数，编译器会将函数类型(包括函数名字，参数类型，返回值类型)放入到符号表中。同样，当编译器看到内联函数，并且对内联函数体进行分析没有发现错误时，也会将内联函数放入符号表。
    当调用一个内联函数的时候，编译器首先确保传入参数类型是正确匹配的，或者如果类型不正完全匹配，但是可以将其转换为正确类型，并且返回值在目标表达式里匹配正确类型，或者可以转换为目标类型，内联函数就会直接替换函数调用，这就消除了函数调用的开销。假如内联函数是成员函数，对象this指针也会被放入合适位置。
    类型检查和类型转换、包括在合适位置放入对象this指针这些都是预处理器不能完成的（不能通过宏来实现）。

- 内联函数省去了函数调用的开销，从而提高程序的执行效率（省去了函数调用时压栈、跳转、返回的开销，以空间换时间）<调用函数：调用前先保存寄存器，并在返回时恢复；可能需要拷贝实参；程序转向一个新的位置继续执行>
- C++语言的函数内联机制既具备宏代码的效率，又增加了安全性，而且可以自由操作类的数据成员。
- 函数被内联后，编译器就可以通过上下文相关的优化技术对结果代码进行更深入的优化。

#### 何时不用内联

- 若函数体内的代码较长，使用内联将导致可执行代码膨胀过大
- 若函数体内出现循环或其他复杂的控制结构，那么执行函数体内代码的时间将比函数调用的开销大很多，使用内联意义不大（除非在大多数情况下，循环或switch语句从不执行）
- 不要轻易让构造函数和析构函数成为内联（对于析构函数，可能有隐含的成员和基类析构函数被调用）
- 很多编译器不支持内联递归函数（递归层数在编译时可能未知）

#### 内联 vs 宏定义

- 内联在编译时展开，宏在预编译时展开
- 内联函数可直接嵌入到目标代码中，而宏只是一个简单的文本替换
- 内联函数可以完成类型检测、语句是否正确等编译功能，而宏不具有
- 内联函数是函数，而宏不是
- 内联函数定义时不会出现二义性，而宏在定义时要小心处理，否则容易出现二义性

### 内存管理

#### 深拷贝 vs 浅拷贝

>[C++深拷贝和浅拷贝（深复制和浅复制）完全攻略](http://m.biancheng.net/view/2336.html)

- 浅拷贝：对内存地址的复制，让目标对象指针和源对象指向同一个内存空间【拷贝指针变量的值】
- 深拷贝：为目标对象分配一块内存，并将源对象所持有的内存拷贝过来。必须<u>显式地定义拷贝构造函数</u>才能达到深拷贝的目的【拷贝指针所指向的内存空间】
  ![image-20200809125853620](C:\Users\YRR\AppData\Roaming\Typora\typora-user-images\image-20200809125853620.png)

**浅拷贝存在的问题**
当内存销毁的时候，指向这片内存的几个指针需要重新定义才可以使用，要不然会成为野指针。
**何时深拷贝？**

- 当类持有其它资源（如动态分配的内存、指向其它数据的指针等）时
- 一个类拥有指针类型的成员变量（让源对象和目标对象的内存相互独立，不受影响）
- 创建对象时需要进行一些预处理（如统计创建过的对象数目、记录创建对象的时间等）

**深拷贝的应用**
STL中的string、vector、stack、set、map等都必须使用深拷贝




#### new vs malloc ▲

> https://www.cnblogs.com/ywliao/articles/8116622.html

对于对象：
new：分配空间，调用构造函数
delete：调用析构函数，释放空间
在堆上创建和释放对象时，
对于基本类型而言：new和delete分配空间，释放空间

|                    | malloc                                                   | new                                                          |
| ------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| 属性               | 是库函数，需要添加头文件                                 | 是操作运算符，可重载                                         |
| 内存分配大小       | 按指定的大小分配，需要显式指定字节数                     | 按数据类型分配，编译器根据类型计算得到，不需要显式指定内存块大小 |
| 内存分配位置       | 堆                                                       | 自由存储区（抽象概念，可以是堆/静态存储区/...看operator new在哪里为对象分配内存） |
| 申请空间时         | 不调用构造函数                                           | 调用构造函数                                                 |
| 内存分配成功返回值 | void* （一般需要进行类型转换）                           | 指定对象的指针（类型安全性）                                 |
| 内存分配失败时     | 内存不够时，返回NULL（因此malloc后最好判断其是否为NULL） | 抛出bad_malloc异常                                           |
| 销毁               | free（不调用析构函数）                                   | delete（调用对象的析构函数）                                 |
| 已分配内存的扩充   | 可以用realloc扩容                                        | 无法直接处理                                                 |
| 申请数组时         | 只能用`sizeof(int)*n`                                    | new[]一次分配所有内存，多次调用构造函数                      |
| 销毁数组           | free                                                     | delete[]，多次调用析构函数，销毁每个对象                     |

```c++
int * a = (int *)malloc(sizeof(int));//分配单个变量
int * arr = (int *)malloc(sizeof(int) * n);//分配一个数组
free(a);//释放变量a
free(arr);//释放数组

A * ptr = new A;//分配单个对象
A * ptr_arr = new A[10];//分配10个A对象
delete ptr;
delete [] ptr_arr;
```


#### 内存泄漏 ▲

内存泄露：申请的内存空间没有被正确释放，导致后续程序里这块内存被永远占用

1. 指针变量超出作用域但其所指的内存没有被释放
2. 指针数组没有使用delete[]释放
3. 一个指针所指的对象没有其他指针指向这个对象，但这个指针转而指向别的对象，原对象所在的内存区域没有被释放

```cpp
Dog *pDog = new Dog();
pDog = nullptr;
```

4. 父类析构函数没有声明成虚函数，而子类中新分配了堆内存。当指向子类对象的父类指针被销毁时
5. shared_ptr中的循环引用
6. 使用指针时抛出异常而导致跳过delete语句

>  https://zhuanlan.zhihu.com/p/79850064

#### 野指针

野指针：指向被释放的或者访问受限内存的指针。
造成野指针的原因：

1. 指针变量没有被初始化（如果值不定，可以初始化为nullptr）
2. 指针被free或者delete后，没有置为nullptr, free和delete只是把指针所指向的内存给释放掉，并没有把指针本身干掉，此时指针指向的是“垃圾”内存。释放后的指针应该被置为nullptr. (悬垂指针)
3. 指针操作超越了变量的作用范围，比如返回指向栈内存的指针就是野指针。

#### struct vs class

唯一的区别是默认的访问权限不同，struct的默认访问权限和默认继承访问权限为public，而class为private

#### 引用 vs 指针

引用：一个对象的别名，本身不是一个对象，必须初始化

- 同：两者都是对内存的间接访问
- 异：
  - 引用：“绑定”内存中的某个对象；指针：“指向”内存中的某个对象
  - 指针是一个对象，运行赋值拷贝，可以指向几个不同的对象；引用不是对象，不能重新绑定到另一个对象上
  - 指针可以不初始化，但引用必须初始化
  - 有指针的指针，但不能有引用的引用（引用本身不是一个对象）

### 类

#### 构造函数不能是const、static、虚函数

构造函数不能是const、static、虚函数

- 创建类的一个const对象时，直到构造函数完成初始化，对象才真正取得了常量属性（构造函数在const对象的构造过程中可以向其写值）
- static没有this指针

#### 析构函数

在虚基类中，如果不提供函数的缺省实现，一定要定义成纯虚函数，否则会出错`undefined reference to 'vtable for Shape'`。析构函数可以是纯虚的，但纯虚析构函数必须有定义体，因为析构函数的调用在子类中是隐含的

```cpp
class Shape{
public:
    virtual double getarea()=0;
    virtual ~Shape()=0;//没法直接在此处加定义体
};
Shape::~Shape(){}; //纯虚析构函数必须有定义体
```



#### 可以显式调用析构函数吗？

可以通过对象调用析构函数，也可以通过对象的指针或引用调用析构函数。
与调用destroy类似，调用析构函数可以清除给定对象，但不会释放该对象所在的空间。需要的话可以重新使用该空间。
（调用析构函数会销毁对象，但不会释放内存）

- 显式调用时，析构函数相当于一个普通的成员函数。调用析构函数会销毁对象，但不会释放内存。在对象生命周期结束后，编译器会隐式调用析构函数，释放栈内存
  重复释放堆内存
- 用户显式调用析构函数的时候，只单纯执行析构函数内的语句，不会释放栈内存

- 用delete释放指针所指空间，不改变指针的值（成为野指针），建议delete之后手动将指针置为NULL，并在delete之前用if语句加以判断，防止程序崩溃；
- 可以显式调用析构函数，但是编译器仅调用用户定义的部分，不调用系统隐含的析构函数，显式调用析构函数之后对象仍存在，只是释放了堆内存（如果有delete相关语句），仍然可以使用对象的其他部分，在对象生命周期结束时还会再调用系统隐含的析构函数以及用户定义的析构函数；
- 如想限制对象的生命周期或提前结束对象生命周期，请使用代码块（大括号），不要显式调用析构函数，但是显式调用析构函数确实可以“清理”诸如链表之类的对象（因为链表的节点都是动态分配的），当然，如果没有动态分配空间，自己编写析构函数的意义也不大。

#### 不存在基类向派生类的隐式类型转换

每个子类对象都包含一个父类部分，父类的引用或指针可以绑定到该父类部分上。一个基类的对象既可以以独立的形式存在，又可以作为派生类对象的一部分存在。
因为一个基类对象可能是派生类对象的一部分，也可能不是，所以不存在基类向派生类的自动类型转换
即使一个基类指针或引用绑定在一个派生类对象上，也不能实现基类向派生类的转换。

```cpp
Base base;
//Derived* derived = &base; //错
//Derived& derived = base;  //错
Derived derived;
Base * base1 = &derived;//对
//Derived *derived1 = base1;//错，基类不能向派生类的转换。
```

编译器只能通过检查指针或引用的静态类型来推断该转换是否合法。可采用dynamic_cast请求类型转换，该转换的安全检查在运行时执行。如果基类向派生类的转换是安全的，则可以使用static_cast强制覆盖编译器的检查工作。

派生类向基类的自动类型转换只对指针或引用类型有效，对象之间不存在类型转换。



#### 虚函数 vs 纯虚函数

纯虚函数：在基类中没有定义的虚函数，要求任何派生类都要定义自己的实现方法。在基类中实现纯虚函数的方法是在函数的原型后面加=0。让基类不可实例化

1. 为了方法使用多态特性，通常需要在基类中定义虚函数
2. 但是有的时候，基类本身生成对象是不合理的，比方说动物有猫、狗等，但动物本身生成对象是不合常理的
3. 纯虚函数一定没有定义，纯虚函数用来规范派生类的行为，即接口。包含纯虚函数的类是抽象类，抽象类不能定义实例，但可以声明指向实现该抽象类的具体类的指针或引用。

纯虚函数调用会发生什么，子类重写纯虚函数是在什么时候进行覆盖的，可不可能在期间调用纯虚函数

#### 虚函数的实现▲

> https://blog.csdn.net/lyztyycode/article/details/81326699?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

什么是虚函数？函数重载、覆盖、隐藏？虚函数如何创建、如何继承？如何访问？

虚函数：被virtual关键字修饰的成员函数

<u>创建</u>：每个含有虚函数的类都会有一个虚函数表与之对应，虚函数表是指针数组，数组中每个元素对应一个虚函数的函数指针。类创建一个对象的时候，会生成一个虚表指针，指向该类的虚函数表（同一个类的对象共用一个虚函数表）

<u>继承</u>：子类继承带有虚函数的父类时，首先会复制父类的虚函数表，然后把子类中已经重写的虚函数对应的函数指针替换掉，如果子类中有新的虚函数，则追加子类虚函数指针

<u>访问</u>：

- 当通过类对象调用一个虚函数时，直接调用该类对应的虚函数，这是静态绑定，没有用到多态
- 当通过指向对象的指针或引用调用虚函数，程序将根据对象类型来调用相应的虚函数，此时是动态绑定，体现了多态。



#### 不能声明为虚函数的函数

任何构造函数之外的非静态成员函数都可以是虚函数
虚函数是在运行期动态绑定的
**不能声明为虚函数的有**：普通函数（非成员函数）；静态成员函数；内联成员函数；构造函数；友元函数
虚函数是通过继承体现多态的，没有继承特性的函数也没有虚函数的说法

- **普通函数**：普通函数只能被重载，而不能被重写，编译器会在编译时绑定函数
- **静态成员函数**：没有this指针，属于某个类，而不属于某个对象
- **内联函数**：inline函数在编译时被展开，虚函数在运行时才动态绑定
- **构造函数**：1）构造函数不能被继承，2）构造函数用来初始化对象，只有在一个对象生成之后才能发挥多态的作用，如果将构造函数声明为虚函数，则表现为在对象还没有生成的时候来定义它的多态，这两点是不统一的。（调用构造函数时，虚表指针没有在对象的内存空间中，必须要构造函数调用完成后才会形成虚表指针）
- **友元函数**：友元函数不属于类的成员函数，不能被继承

【注】<u>析构函数通常声明为虚函数</u>

#### 析构函数应该是虚函数

这个是解决  删除指向子类对象的父类指针 ~~用父类指针删除其所指的子类对象~~ 可能出现的问题

如果析构函数不被声明成虚函数，则编译器实施静态绑定，在删除基类指针时，只会调用基类的析构函数而不调用派生类析构函数，这样就会造成派生类对象析构不完全。

- 子类分配的内存不能被释放

- ```cpp
  class Animal{
  class Animal{
  public:
      virtual void bark()=0;
      Animal(){
          cout<<"Animal ctor"<<endl;
      }
       ~Animal(){
          cout<<"Animal dctor"<<endl;
      };
  };
  class Cat:public Animal{
  public:
      //int a;
      Cat(){
          cout<<"Cat ctor"<<endl;
      }
      void bark(){
          cout<<"miao"<<endl;
      }
      ~Cat(){
          cout<<"Cat dctor"<<endl;
      };
  };
  class Dog: public Animal{
  private:
      int *dd;
  public:
      Dog(){
          dd = new int[200];
          cout<<"Dog ctor"<<endl;
      }
      void bark(){
          cout<<"wang"<<endl;
      }
      ~Dog(){
          delete[] dd;
          cout<<"Dog dctor"<<endl;
      };
  };
  int main(){
      Animal *pA = new Dog();
      delete pA;
      /* 输出：
      Animal ctor
      Dog ctor
      Animal dctor （没有调用Dog的析构函数）
      */
      
  	Animal *animals[2];
      animals[0] = new Cat();//&cat;
      animals[1] = new Dog();//&dog;
      delete[] animals;
      /* 内存泄漏 堆对象Dog中new的dd没有被delete
      Process returned -1073741819 (0xC0000005)
      */
      
      Cat cat; //栈对象
      Dog dog; //栈对象
      Animal *animals[2];
      animals[0] = &cat;
      animals[1] = &dog;
      delete[] animals;
      cat.bark();
      cout<<endl;
      /*
      Animal ctor
      Cat ctor
      Animal ctor
      Dog ctor
      miao
  
      Dog dctor  //退出main函数的时候调用析构函数，删除栈上的对象
      Animal dctor
      Cat dctor
      Animal dctor
      */
  }
  ```



#### 构造函数中调用虚函数

构造函数不能是虚函数，但构造函数里能调用虚函数

```cpp
class Base{
public:
    Base(){
        func();
    }
    virtual void func(){
        cout<<"Base func"<<endl;
    }
};
class Derived : public Base{
public:
    Derived(){
    }
    void func(){
        cout<<"Derived func"<<endl;
    }
};
int main(){
    Base *p = new Derived;
    return 0;
}
//输出：Base func
//父类指针生成子类对象，会隐式调用父类的构造函数，尽管对象是子类，但是在构造父类部分时，还只是Base，所以调用的是父类的虚函数
```

#### 友元

友元：允许其他类或者函数访问它的非公有成员

- 友元**声明**只能出现在类定义的内部（友元的声明仅仅指定了访问权限，而非真正意义上的声明），而定义在类内或者类外没有区别
- 友元不是类的成员，不受它所在区域访问控制级别的约束
- 友元关系是单向的，不能传递，不能继承

优：能够提高效率，表达清晰、简单；
缺：破坏了类的封装

应用：

- 为类重载二元运算符时（带两个参数的运算符）常常需要友元【计算两个点的距离：point类，distance友元函数】
- 两个类要共享数据的时候【遥控器类、电视机类，遥控器可以改变电视机状态】

```cpp
class wheel;
class car{
public:
    car(char *pn);
    void run(wheel &w); //成员函数，做成wheel类中友元函数实现
private:
    char name[20];
};
class wheel{
public:
    wheel(int s);
    friend void car::run(wheel &w);   //这里把car类的成员函数做了友元函数。
private:
    int speed;
};
```



### STL容器

#### 迭代器失效情况

- vector：添加、删除都可能使容器部分或全部迭代器失效
  1. 插入push_back元素后，若capacity返回值与插入前不同，则需要重新加载整个容器，所有迭代器失效；若与插入前相同，则插入位置之后元素的迭代器失效，end返回的迭代器失效
  2. 删除erase/pop_back元素后，指向删除点及其之后元素的迭代器都失效
- deque
  1. 首部/尾部插入元素不会使任何迭代器失效
  2. 在首部/尾部删除元素，只会使指向被删除元素的迭代器失效
  3. 在容器的其他任何位置插入或删除都会导致所有迭代器失效
- list：对于节点式容器(map, list, set)元素的删除，插入操作会导致指向该元素的迭代器失效，其他元素迭代器不受影响



#### push_back vs emplace_back

push_back()首先需要调用构造函数构造一个临时对象，然后调用拷贝构造函数将这个临时对象放入容器中，然后释放临时变量。这样造成的问题就是临时变量申请资源的浪费。

emplace_back()在容器尾部添加一个元素，这个元素原地构造，不需要触发拷贝构造和转移构造。而且调用形式更加简洁，直接根据参数初始化临时对象的成员。

#### map vs set

同：都是关联容器，底层实现都是红黑树，元素根据键排序

异：

- set：元素是键，不存在重复元素，不支持下标操作，不能通过迭代器改变set的值，因为set的值就是键
- map：元素是key-value键值对，key可以作为下标

#### 红黑树

性质：

1. 每个节点要么红，要么黑
2. 根节点是黑的
3. 每个叶节点（NIL）都为黑
4. 每个红色节点的两个子节点必为黑色
5. 任意一个节点到每个叶子节点的路径都包含相同数量的黑节点

**左旋**：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。

**右旋**：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。



### C++11新特性

- **nullptr**：空指针
- **constexpr**：将表达式/函数编译为常量结果
- **auto**：变量类型推导，让编译器自动分析某个变量的类型
- **decltype**：变量/表达式类型推导，让编译器自动分析表达式的类型得到相应类型（不用计算表达式的值）
- **范围for语句**：简化遍历序列的操作 `for(auto c : str)`
- **委托构造**：同个类中的一个构造函数可以调用另一个构造函数
- **继承构造**：子类可以直接调用父类的构造函数  `using Base::Base;`
- **Lambda表达式**：用于定义并创建匿名的函数对象，以简化编程工作
- **智能指针**：自动回收指针，防止内存泄漏
- **元组tuple**：可以存放任意数量的不同类型的元素
- **move**：将一个左值强制转化为右值引用，继而可以通过右值引用使用该值

#### 右值

左值：表达式结束后依然存在的持久对象，变量

后置：表达式结束后就不再存在的临时对象（不能取地址），字面常量或表达式求值过程中创建的临时对象

右值引用：只能绑定到一个将要销毁的临时对象，可以绑定到要求转换的表达式、字面常量或返回右值的表达式

```cpp
int i = 42;
int &l = i;//对，左值引用
const int &lr = i*42;//对，可以将一个const引用绑定到一个右值上
//int &&r = i; //错，不能将右值引用绑定到左值上，不能绑定到变量上，即使变量是右值引用类型也不行
int &&rr = i*42;//对，可以将右值引用绑定到乘法结果上
```



#### Lambda表达式

定义并创建匿名的函数对象，用于替换独立函数或者函数对象，以简化编程工作（快速实现一些小功能但并不想为此单独编写整个函数）

```cpp
// 完整语法
[ capture-list ] ( params ) mutable(optional) constexpr(optional,c++17) exception attribute -> return type { body }

[](int x, int y)->int{return x+y;}

// 可选的简化语法
[ capture-list ] ( params ) -> ret { body }     
[ capture-list ] ( params ) { body }    
[ capture-list ] { body }
```

- `[函数对象参数]`：设置读取变量的方式（按值/址&）
  []表示不截取任何变量；
  [&]截取外部作用域中所有变量，并作为引用在函数体中使用；
  [=].....，拷贝一份在函数体内使用
  [=, &num] 截取外部作用域中所有变量，并拷贝一份在函数体中使用，但是对num变量使用引用
  [k] 截取k变量并且拷贝一份在函数体重使用，同时不截取其他变量
  [this] 截取当前类中的this指针。如果已经使用了&或者=就默认添加此选项。
- `(parameter list)`：形参列表（可省略）
- `->return type`：返回值类型（可省略）
- `{function body}`：函数体

```cpp
auto ptr = []() {cout << "hello" << endl; };	//lambda表达式
ptr();//调用函数

auto fun = [](int x, int y)->int {return x+y;};	//带参数的lambda表达式
auto z=fun(3, 4);
cout << z << endl; //7


int x=10;
//1.复制捕捉x，函数体内不能修改x
auto sum1=[x](int a, int b)->int{return x+a+b;};
cout<<sum1(1,2)<<endl;// 13
cout<<x<<endl;//x=10
//2.复制捕捉x，利用mutable修改函数体内的x，但不影响外部x的值
auto sum2=[x](int a, int b)mutable->int{x=20;return x+a+b;};
cout<<sum2(1,2)<<endl;// 23
cout<<x<<endl;//x=10
//3.引用捕捉x，函数体内修改x，影响外部x的值
auto sum3=[&x](int a, int b)->int{x=20; return x+a+b;};
cout<<sum3(1,2)<<endl;// 23
cout<<x<<endl;//x=20
```



从C++14开始，lambda表达式支持泛型：其参数可以使用自动推断类型的功能，而不需要显示地声明具体类型。这就如同函数模板一样，参数要使用类型自动推断功能，只需要将其类型指定为auto，类型推断规则与函数模板一样。这里给出一个简单例子：

```cpp
auto add = [](auto x, auto y) { return x + y; };

int x = add(2,3);   // 5
double y = add(2.5,3.5);  // 6.0
```

 

#### 可调用对象

可调用对象：函数、函数指针、重载了函数调用运算符的类、lambda表达式

- 构造函数
- 析构函数
- 函数对象
- lambda表达式

#### RAII 资源获取即初始化

C++资源管理、避免内存泄漏的方法（Java、Python有垃圾回收机制）

利用了类超出作用域时会自动调用析构函数的特点。把资源用类封装起来，在构造函数中获取对应的资源，在生命期内控制对资源的访问，使之始终保持有效，在析构函数中释放资源。<资源：网络套接字、互斥锁、文件句柄、内存等>

智能指针、模板类lock_guard（而mutex创建互斥量时通过调用成员函数lock()上锁、unlock()解锁，不易管理）

java、python具备垃圾回收机制

#### 智能指针及其实现原理 ▲

> [详解C++11智能指针](https://www.cnblogs.com/WindSun/p/11444429.html)

动态管理内存的时候可能会出现两个问题：

1. 忘记释放内存，导致内存泄漏
2. 在还有其他指针指向内存的情况下，释放了这个内存

智能指针的把普通的指针封装成一个类，当超出类的作用域时，类会自动调用析构函数释放资源。目的就是为了更安全地使用动态内存。

- unique_ptr（替代了auto_ptr）：是独占式的， 就是一个对象只能被一个智能指针拥有。auto_ptr 使用拷贝移动，拷贝后原对象变得无效，再次访问原对象时会导致程序崩溃；unique_ptr 则禁止了拷贝语义，但提供了移动语义，即可以使用 std::move() 进行控制权限的转移

```cpp
unique_ptr<string> p1(new string("hello"));
unique_ptr<string> p2;
//p2 = p1; //eg1:错误，避免了p1不再指向有效数据的问题
unique_ptr<string> p3;
p3 = unique_ptr<string>(new string("ok")); //eg2:编译正确，允许源unique_ptr是个临时右值（临时对象在其所有权让给 p3后就会被销毁）
```

- shared_ptr：允许多个指针指向同一对象,该对象和其相关资源会在“最后一个引用被销毁”时候释放。采用**引用计数**的方法记录当前内存资源被多少个智能指针引用。当新增一个时引用计数+1，当reset()时引用计数-1。只有引用计数为0时，智能指针才会自动释放引用的内存资源。（但是两个对象相互使用一个shared_ptr成员变量指向对方，会造成**循环引用**，会导致内存泄漏）
- weak_ptr：一种弱引用，指向shared_ptr所管理的对象，打破循环引用（死锁，内存泄漏） 主要用于监测shared_ptr中所管理的指针资源是否存在

> https://blog.csdn.net/king_way/article/details/95536938

```cpp
#include <iostream>
#include <bits/stdc++.h>
using namespace std;
class B;
class A {
public:
    shared_ptr<B> ptrB;
    A(){
        cout<<"A ctor"<<endl;
    }
    ~A(){
        cout<<"A dctor"<<endl;
    }
};

class B {
public:
    weak_ptr<A> ptrA;
    //shared_ptr<A> ptrA;
    B(){
        cout<<"B ctor"<<endl;
    }
    ~B(){
        cout<<"B dctor"<<endl;
    }
};

int main() {
    {
        shared_ptr<A> pA(new A);
        shared_ptr<B> pB(new B);
        cout<<pA.use_count()<<endl;
        cout<<pB.use_count()<<endl;
        pA->ptrB = pB;
        pB->ptrA = pA;
        cout<<pA.use_count()<<endl;
        cout<<pB.use_count()<<endl;
    }
    return 0;
} 
/*
A ctor
B ctor
1
1
1
2
A dctor
B dctor
*/
```



#### 类型转换

const_cast, static_cast, dynamic_cast, reinterpret_cast

1. **const_cast**
   去掉const性质，只能改变对象的底层const。只能改变表达式的常量属性，不能改变表达式的类型。

```cpp
char c ='2';
const char *pc=&c;
char *p = const_cast<char*>(pc);
*p = 'a';
```

const_cast 常用于有函数重载的上下文中

2. **static_cast**
   静态转换（在编译期间转换）基本类型转换

- 基本数据类型转换，例如 short 转 int、int 转 double等；
- 父类和子类之间指针或引用的转换，但没有运行时类型检查来保证转换的安全性
  向上转换（子类指针/引用转换成父类的）：安全
  向下转换（父类指针/引用转换为子类的）：由于没有运行时类型检查，所以不安全
- void 指针和具体类型指针之间的转换，例如`void *`转`int *`、`char *`转`void *`等；必须确保转换后所得类型就是指针所指类型，强制转换的结果将与原始地址值相等
  <任何非常量对象的地址都能存入void*>
- 可以显式地将一个左值转换为一个右值引用（move函数）
- 不能在两个具体类型的指针间转换
- 不能将整数转换为指针类型
  

3. **dynamic_cast**
   动态类型转换（运行时检查类型安全），多态类之间的类型转换，只能转换指针或引用
   （1）`dynamic_cast<type*>e`  e必须是有效指针，失败返回0
   （2）`dynamic_cast<type&>e`  e必须是左值，因为不存在空引用，所以失败抛出bad_cast异常
   （3）`dynamic_cast<type&&>e`  e不能是左值，失败抛出bad_cast异常
   type必须是类类型（须含有**虚函数**）
   e的类型是type的公有子类/公有父类/type类型。

- 主要用于类层次间的上下行转换，也可用于类之间的交叉转换
  1. 向上转换：dynamic_cast和static_cast效果一样
  2. 下行转换：如果向下转换安全（基类指针/引用确实指向一个派生类对象），此时返回转换后的指针，否则返回0（基类指针/引用没有指向一个派生类对象）。dynamic_cast具有类型检查功能，比static_cast更安全。
  3. 交叉转换

```cpp
class Base{
public:
    virtual void fun(){};
};
class Derived1:public Base{
};
class Derived2: public Base{};
void foo(){
    Derived1 *pd1 = new Derived1;
    Derived2 *pd2 = dynamic_cast<Derived1*>(pd1);//交叉转换
    delete pd1;
 }
 
class Base1{
public:
    virtual void g(){}；
 };
 //多继承
 class MultiDerived: public Base, public Base1{
 };
 void foo_multi(){
    Base* pbmd = new MultiDerived;
    MultiDerived* pmd = dynamic_cast<MultiDerived*>(pbmd);
    Base1* pb1 = dynamic_cast<MultiDerived*>(pbmd);//如果要转化为Base的兄弟类Base1，必须使用dynamic_cast
 }
```



4. **reinterpret_cast**
   为运算对象的位模式提供较低层次上的重新解释。不同类型的指针类型转换（不常用）





## 编译、链接、装载与库

### 编译与链接

#### 编译 vs 链接

- **编译**(compile)：由编译程序把源文件编译成中间代码文件（object file，windows下为.obj，unix、Linux下为.o）
  编译时编译器需要<u>检查语法的正确、函数与变量声明的正确</u>
- **链接**(link)：由链接程序将编译后形成的大量的中间目标文件以及它们所需的库函数链接在一起（这里也包括.lib/.a文件，.lib/.a文件件本质上就是打包的.obj文件集合）
  链接是<u>让目标文件之间相互链接自己所需的函数和全局变量</u>（函数可能来源于其它目标文件或库函数）

#### 代码文件到可执行程序的过程 ▲

> https://www.cnblogs.com/xcywt/p/4951290.html

C++完整编译过程：预编译->编译->汇编->链接

- **预编译**：把头文件、宏定义等以#开头的预编译指令替换，删除注释。【得到.i文件】

- **编译**：编译器对预编译完的文件进行词法分析、语法分析、语义分析以及相应的优化，产生汇编代码文件。【得到.s文件】

- **汇编**：将编译完的汇编代码文件翻译成机器指令，生成可重定位目标程序的.o文件【得到.o文件】

  该文件为二进制文件，字节编码是机器指令。汇编器没有复杂的语法、语义，不需要做指令优化，只是根据汇编指令和机器指令对照表一一翻译。

- **链接**：通过链接器将一个个目标文件（或许还会有库文件）链接在一起生成一个完整的可执行程序。【得到.out/.exe文件】

#### 编译器

> https://www.cnblogs.com/xcywt/p/4902789.html

1. **词法分析**：利用有限状态机将源代码字符序列分割为一系列的记号。把标识符放在符号表，数字、字符串等字面量放在文字表

2. **语法分析**：产生语法树（以表达式为节点的树）。对符号含义、优先级进行区分，判断括号是否匹配、表达式是否缺少操作符等

3. **语义分析**：将语法树中节点表明含义（为语法树的表达式标明类型）。编译期分析的是静态语义。
   - 静态语义：编译阶段可以确定的语义，包括声明和类型的匹配、类型的转换
   - 动态语义：运行期才能确定的语义，eg.将0作为除数
4. **中间语言生成**：将整个语法树转换成中间代码（语法树的顺序表示），会在源码级别进行优化。eg.(2+6)会被优化为8
5. **目标代码生成与优化**：利用代码生成器将中间代码转换成目标机器代码，利用目标代码优化器对目标代码进行优化(eg.选择合适的寻址方式、使用位移代替乘法、删除多余的指令等)



- 现在的编译器可以将源代码文件编译程一个未链接的目标文件，然后由链接器最终将这些目标文件链接起来形成可执行文件

#### ELF文件结构

PE-COFF/ELF文件：可重定位文件(目标文件.obj/.o，静态链接库.lib/.a)、可执行文件(.exe)、共享目标文件(动态链接库.dll/.so)、核心转储文件

目标文件：编译后未链接的中间文件，与可执行文件的内容和结构很相似

- ELF文件头：描述整个文件的属性（ELF魔数<16字节：ELF标识码、字长、字节序大小端、文件版本>、程序头入口、段表位置、段表字符串表下标等）
- 常见的段：
  - 代码段(.text)
  - 重定位表(.rel.text)：每个要重定位的ELF段都有一个对应的重定位表（.text中有要被重定位的地方就会有对应的.rel.text表）每个重定位的入口都是对一个符号的引用，链接器会查找所有输入目标文件的符号表组成的全局符号表，找到相应的待引用符号的目标地址，进行重定位
  - 数据段(.data)：保存已经初始化的全局变量和局部静态变量
  - 只读数据段(.rodata)：存放只读变量（const修饰的变量）和字符串常量 (操作系统在加载时可以将该段属性映射为只读，保证了程序的安全性)
  - BSS段(.bss)：存放未初始化的全局变量和局部静态变量（默认值都为0，没必要用.data存放0），.bss段为它们预留了位置但不占空间，到最终链接成可执行文件时再在.bss段分配空间，在程序运行的时候占内存
  - 符号表(.symtab)
  - 字符串表(.strtab)：存储ELF文件中用到的各种字符串
  - 段名表(.shstrtab)
- 段表：保存段的基本属性，记录每个段的下标、段名、段长、偏移、读写权限等

#### 符号修饰

C++采用命名空间来减少多模块的符号冲突。通过符号修饰允许多个不同参数类型的函数有同样的名字（函数重载），允许在不同的名称空间有多个同样名字的符号

GCC编译器下：`int C::CF::func(int)`->`_ZN1C2CF4funcEi`

不同编译器下有不同的符号修饰方法，因此不同编译器编译的产生的目标文件可能无法正常链接

`extern "C"{}` 使括号内部的代码以C语言代码处理，C++的符号修饰机制不会起作用

#### 重复代码消除

C++编译器在很多时候会产生重复代码：如模板、外部内联函数、虚函数表等都可能在不用编译单元力生成相同的代码。可能造成1.空间浪费、2.地址较易出错、3.指令运行效率较低

解决方法：将每个模板的实例代码都单独存放在一个段里，每个段只包含一个模板实例(如int类型和float类型实例化的模板函数，分别生成两个段`.temp.add<int>`,`.temp.add<float>`）。链接器在最终链接的时候区分相同的模板实例段，再将它们合并到最后的代码段。外部内联函数、默认构造函数、默认拷贝构造函数、赋值操作符等都是采用类似的方法。



#### 静态语言 vs 动态语言

- 静态语言（强类型语言）：在编译时变量的数据类型即可确定的语言，大多静态语言要求在使用变量之前必须声明数据类型。如C、C++、Java
- 动态语言（弱类型语言）：在运行时确定数据类型的语言，变量使用之前不需要类型声明，不必每次都指定类型，代码开发快， 如Python、JavaScript

编译型语言：源代码一次性编译程可执行的机器码 C、C++

解释型语言：使用专门的解释器将源程序逐行解释长特定平台的机器码并立即执行。Python

java编译成.class文件（但不是机器可识别的语言），需要jvm解释实现跨平台执行



#### 装载

物理内存：通过物理内存条而获得的内存空间，CPU地址线可以直接进行寻址的内存空间

虚拟内存：指将硬盘的一块区域划分来作为内存。

虚拟地址空间(VAS)的大小由计算机硬件的寻址空间大小决定（32位的硬件平台决定了虚拟地址空间位0到$2^{32}-1$，即4GB虚拟空间大小）一般来说指针大小的位数与虚拟空间的位数相同（32位平台下指针为32位，即4字节）

4GB的虚拟空间一部分由操作系统占用(linux下1GB)，原则上进程最多可使用3GB虚拟空间

32位CPU下，程序使用的计算机内存空间可以超过４GB，采用36位的物理地址并使用新的映射方式可以访问64GB的物理内存（PAE物理地址扩展）





### 内存管理

操作系统通过给进程空间划分出若干个VMA（虚拟内存地址）来管理进程的虚拟空间，基本原则是将相同权限属性的、有相同映像文件的映射成一个VMA。

从高地址到低地址的分布为栈、堆、数据段（BSS被合并到数据段里）、代码段

<img src="https://www.linuxidc.com/upload/2015_02/150225122528321.png" alt="img" style="zoom:67%;" />

页是映射的最小单位，默认页大小为4096字节

#### 进程栈初始化

操作系统在进程启动前需要将系统环境变量、进程的运行参数等运行环境信息提前保存到进程的虚拟空间的栈中。

栈顶寄存器esp指向的位置是初始化后的栈顶，记录命令行参数的数量，指向这些参数字符串的指针，0，指向环境变量的指针，0表示结束。进程启动后，程序库部分会把栈里的初始化信息中的参数信息传给main函数，也就是argc和argv，分别对应命令行参数数量和参数字符串的指针数组

#### 栈（从高地址向低地址生长）

栈保存了一个函数调用所需维护的信息（栈帧），包括函数的返回地址和参数，临时变量（函数的非静态局部变量、编译器自动生成的其他临时变量），保存的上下文（包括函数调用前后需要保持不变的寄存器）

一个函数的栈帧由ebp和esp两个寄存器划定范围。esp寄存器始终指向栈顶，ebp指向调用该函数前的ebp值。

函数执行的过程：

1. 把调用该函数前的ebp压入栈中，让ebp指向当前的栈顶（esp）
2. 在栈上分配临时空间，存储局部变量、某些临时数据及调试信息
3. 可能要保存一些寄存器原本的值，以便在退出函数时恢复
4. 从栈上恢复寄存器
5. 恢复进入函数前的esp和ebp
6. 使用ret指令返回

在C++里返回一个对象时，需要经过2次拷贝构造函数的调用才能完成返回对象的传递。一次拷贝到栈上的临时对象里，另一次把临时对象拷贝到存储返回值的对象里。

#### 堆

栈上的数据在函数返回的时候就被释放掉，所以无法将数据传递至函数外部。而全局变量没法动态产生，只能在编译时定义，因此采用堆

问题：如果进程的内存管理交给操作系统内核做，每次程序申请/释放堆空间都需要进行系统调用，性能开销大。

解决：程序向操作系统申请一块适当大小的堆空间，然后又程序自己管理这块空间（管理对空间分配的往往是程序的运行库）【运行库从操作系统“批发”较大的堆空间，“零售”给程序用，全部“售完”后再向操作系统“进货”】

**Linux进程堆管理**

mmap()向操作系统申请一段虚拟地址空间，这块空间可以映射到某个文件，也可以不映射到某个文件（匿名空间）。匿名空间可以拿来作为堆空间。（mmap申请空间的起始地址和大小都必须是系统页的大小的整数倍）

malloc()函数处理用户的空间请求：

- 对于小于128KB的请求：再现有的对空间里，按照堆分配算法为其分配一块空间并返回
- 对于大于128KB的请求：使用mmap()函数为其分配一块匿名空间，然后在匿名空间中为用户分配空间

**Windows进程堆管理**

VirtualAlloc()与mmap相似，向系统预留了一块虚拟地址（不一定只用于堆）

每个进程在启动时会创建一个默认的堆，直到进程结束都一直存在（默认为1MB），如果堆空间不够，则通过VirtualAlloc向系统申请更多的空间。进程中可能存在多个堆。



- 不能重复释放堆里的同一片内存
- 堆不总是向上增长的，linux中用brk方法分配堆空间是向上的，但windows里HeapCreate产生的堆不遵照向上增长的规律
- 调用malloc不一定会调用到系统调用或API：如果当前进程向操作系统“批发”的空间还够，则不会；若不够，只能通过系统调用或API向操作系统“进货”
- malloc申请的内存在进程结束后不存在：进程结束后，所有与进程相关的资源，包括进程的地址空间、物理内存、打开的文件、网络链接等都被操作系统关闭或收回。
- malloc申请的空间是否连续？若指虚拟空间，则是连续的（每次malloc分配的后返回的空间都可以看成一块连续的地址）；若指物理空间，则不一定连续（一块连续的虚拟空间可能由多个不连续的物理页拼凑而成）

**堆分配**

1. 空闲链表：把堆中各个空闲块按照链表的方式连接起来，当用户申请一块空间时，可以遍历整个列表，直到找到合适大小的块并将它拆分；当用户释放空间时，将它合并大空闲链表中。（请求k字节的空间时，实际分配k+4个字节，4个字节用于存储分配的大小，释放内存时，根据4个字节的值知道内存块的大小）
2. 位图：将整个堆划分为大量的块，每个块的大小相同。用户请求内存时，总是分配整数个块的空间给用户。使用一个整数数组来记录块的使用信息，每个块只有头、主体、空闲3种状态，因此只使用2位即可表示一个块
3. 对象池

### 程序运行

#### 进程的创建过程

1. 创建一个独立的虚拟地址空间：创建映射函数所需的相应的数据结构（**建立虚拟空间到物理内存的映射关系**）
2. 读取可执行文件头，并**建立虚拟空间与可执行文件的映射关系**（需要知道程序所需的页在可执行文件中的哪个位置）
3. 将CPU的指令寄存器设为可执行文件的入口地址，启动执行。操作系统通过CPU指令寄存器将控制权转交给进程，由此进程开始执行（OS层面设计内核堆栈和用户堆栈的切换、CPU运行权限的切换）

#### 程序运行步骤

1. 操作系统创建进程后，把控制权交给程序入口（这个入口往往是运行库中的某个入口函数）
2. 入口函数对运行库和程序运行环境进行初始化，包括堆、I/O、线程、全局变量构造等
3. 入口函数在完成初始化之后，调用main函数，正式开始执行程序主体部分
4. main函数执行完毕后，返回到入口函数，入口函数进行清理工作，包括全局变量析构、堆销毁、关闭I/O等，然后进行系统调用结束进程

#### 静态链接 vs 动态链接 ▲

>[link1](https://www.cnblogs.com/skynet/p/3372855.html)
>[link2](https://blog.csdn.net/sinat_33878959/article/details/81224155)

- **静态库**：静态库在程序编译时会被链接到目标代码中，程序运行时将不再需要改静态库。把.lib/.a文件中用到的<u>函数代码</u>直接链接进目标程序，对函数库的链接在**编译期**完成，程序运行时与函数库再无瓜葛
  【特点】

         1. 编译成功的可执行文件可以独立运行，代码装载效率高，移植比较方便，而不再需要向外部要求读取函数库的内容
            2. 全量更新：如果函数库更新，需要重新编译。(可维护性差)
               3. 空间浪费：静态库比较浪费空间和资源，所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件

- **动态库**：动态库在程序编译时并不会被链接到目标代码中，而是在程序运行时才被载入。把调用函数所在的<u>.dll/.so文件、其在文件中的位置等信息</u>链接进目标程序，程序**运行期**再从dll中寻找相应的函数代码（使用动态库时往往提供两个文件：引入库<需要调用的函数和变量符号名>和dll<包含实际的函数和数据>）
  【特点】

      1. **增量更新**：产品升级时只要替换对应动态库即可，不必重新编译整个可执行文件。

  2. **代码共享**：所有引用该动态库的可执行文件共享一份相同的代码和数据（动态库可以实现**进程之间的资源共享**，所以又被称为共享库）使用动态库会更加节省内存并减少页面交换
  3. 可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）
  4. 无法单独运行：当可执行文件需要使用到函数库的机制时，程序才会去读取函数库来使用；也就是说可执行文件无法单独运行。

## 数据库

#### 数据库类型

1. 关系型数据库：适合存储结构化数据。MySQL, SQL Server, Oracle
2. 非关系型数据库：存储非结构化数据。mongodb（文档数据库），Redis（Key-Value数据库），HBase，图数据库

#### char vs varchar

- char：定长，适合存储很短的字符串，或者所有值都接近同一长度。因为长度固定，存取速度快。若插入长度<char的固定长度，用空格填充（最多存放255个字符）
- varchar：可变长，比定长类型更省空间，使用额外1或2个字节存储字符串长度。最多存放65532个字符

#### 内连接、左连接、右连接

- 内连接/等值连接 inner join <=>join
只返回两个表中连接字段相等的行。
- 左连接 left join
返回包括左表中的所有记录和右表中连接字段相等的记录。
- 右连接 right join
返回包括右表中的所有记录和左表中连接字段相等的记录。
- 全外连接 full join
返回左右表中所有的记录和左右表中连接字段相等的记录。

#### `union all`  vs  `union`

union all 不会合并重复的记录，效率高

- 尽量用 union all 替换 union（如果检索结果中不会有重复的记录，推荐union all 替换 union。）

```mysql
# 以下语句更优，相当于select * from user where userid=1 or age=10
select * from user where userid=1
union all
select * from user where age = 10  
```

如果使用union，不管检索结果有没有重复，都会尝试进行合并，然后在输出最终结果前进行排序。如果已知检索结果没有重复记录，使用union all 代替union，这样会提高效率。

### 事务

> [深入学习MySQL事务：ACID特性的实现原理](https://www.cnblogs.com/kismetv/p/10331633.html)

#### 事务的四大特性
事务是最小执行单位，不允许分割
ACID：原子性、一致性、隔离性、持久性
- 原子性：一个事务开始后要么全部完成，要么全都不执行 `start transaction;`  `commit;`或`rollback;` `show variables like 'autocommit';` `set autocommit=0;`
- 一致性：事务在执行前后数据库的完整性约束没有被破坏。如：实体完整性(eg.
行的主键存在且唯一)、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（eg.转账前后两个账户金额之和保持不变）
- 隔离性：多个事务并发执行时，一个事务不被其它事务所干扰
- 持久性：一个事务提交后，它对数据库的改变时持久的，即使系统或介质发生故障也不会有任何影响（通过数据库备份与恢复来保证）
#### ACID实现原理
> InnoDB存储引擎提供了两种事务日志
    - redo log（重做日志）用于保证事务持久性
    - undo log（回滚日志）是事务原子性和隔离性实现的基础
1. **原子性**。利用**undo log**：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子
2. **持久性**。利用**redo log**：redo log采用的是WAL（Write-ahead logging，预写式日志），<u>所有修改先写入redo log，再更新到Buffer Pool</u>，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log 需要在事务提交时将日志写入磁盘
3. **隔离性**。保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是可重复读（RR），RR的实现主要基于锁机制、数据的隐藏列、undo log和<u>类next-key lock机制</u>[避免幻读]  锁机制,MVCC保证隔离性
4. **一致性**。
    1. 保证原子性、持久性、隔离性
    2. 数据库本身提供保障，如不允许向整形列插入字符串值、字符串长度不能超过列的限制等
    3. 应用层面进行保障，例如如果转账操作只扣除转账者的余额，需要增加接收者的余额

> 由于数据是存放在磁盘中的，如果每次读写都要磁盘I/O，效率会很低。因此InnoDB采用缓存机制(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。
**[拓] 为什么redo log比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快？**
（1）刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO
（2）刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。

#### 事务并发带来的问题
多个事务多同一数据进行操作
- **脏读**：事务A可以读到事务B中未提交的数据（脏数据）【读到其他事务未提交的数据】
- **不可重复读**：事务A先后两次读取同一个数据的结果不一样【读到其他事务已提交的数据，强调修改】
- **幻读**：事务A按照某个条件先后两次查询数据库，两次查询结果的条数不同【强调增删】


#### 事务的隔离级别
`select @@tx_isolation;`

##### MySQL实现事务隔离的方式
- 未提交读：不加锁
- 已提交读：快照读（普通select）使用MVCC，当前读（select lock in share mode/select for update/update/delete）使用Record Lock，可能出现不可重复读


- 可重复读：快照读使用MVCC，当前读使用Next-Key Lock

  - 如果读语句使用unique key，则InnoDB会将next-key lock降级为record lock，仅锁住索引本身而不是范围，因为唯一索引保证了数据不会重复，同一条数据的gap不会再插入新的数据。（通过主键或唯一索引来锁定不存在的值，也会产生gap锁定）
  - 如果是其他查询，则使用next-key lock（record lock+gap lock），这会导致更新一行锁住两行的现象

- 可串行化：普通select 隐式转换为select ... in share mode，与X锁互斥。如果有未提交的修改，所有读取这些行的select都会被阻塞，没有MVCC

  在每个读的数据行上加共享锁。强制对事务进行排序，使其不发生冲突。

InnoDB的锁是加在索引上的，如果查询/更新没有使用索引，则会锁全表。因为没有使用索引字段查询/更新，InnoDB只好使用主键索引，此时InnoDB无法确定更新条目的gap，只好锁全表（所著所有行和间隙）

1. 当前读：加锁读，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁（MVCC无法解决当前读下的幻读问题）

```mysql
select * from table where ? lock in share mode; #获取行共享锁
select * from table where ? for update;  #获取行排他锁
insert into table values (...);  #获取行排他锁
update table set ? where ? ;  #获取行排他锁
delete from table where ? ;  #获取行排他锁
```

2. 快照读：不显式加lock in share mode和for update的select操作都属于快照读，使用MVCC

### 锁

> [幻读、间隙锁、行锁、next-key lock、加锁规则、间隙锁导致的死锁、隔离级别设置、for update的理解](https://blog.csdn.net/h2604396739/article/details/86518943)

1. record lock：行锁，单行索引记录上的锁

   跟行锁有冲突的是另外一个行锁

2. gap lock：间隙锁，锁定一个范围，但不包括记录本身，开区间( , )。防止幻读

   跟间隙锁存在冲突的是往这个间隙中插入一个记录的操作

3. next-key lock（record lock+gap lock）：锁定一个范围，并锁记录本身，防止幻读

   - 前开后闭区间 ( , ]，查找过程中访问到的对象才会加锁
   - 对于索引上的等值查询，给唯一索引加锁时，退化为record lock
   - 索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为gap lock。

表级锁：将整个表锁定，锁定力度大，并发度低，适合以查询为主，少量更新的应用

行级锁：粒度小，发生锁冲突的概率低、并发度高，加锁慢，容易发生死锁



读锁（共享锁，S锁）多个事务都能读同一数据，但不能修改

写锁（排他锁，X锁）与其他锁互斥，只有获取排他锁的事务可以对数据进行读取和修改

#### 乐观锁 悲观锁

**读取频繁使用乐观锁，写入频繁用悲观锁**

数据库管理系统（DBMS）中的并发控制任务是确保在多个事务同时存取数据库张同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。

- 悲观锁：总认为会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。

  - 实现方式：使用数据库中的锁机制
  - 优：利用数据库中的锁机制实现数据变化的顺序执行
  - 缺：一个事务用悲观锁对数据加锁后，其他事物不能对加锁数据进行除查询外的所有操作。若该事务执行时间很长，必将导致其他事务等待，而导致系统吞吐量下降
  - 适用于：多写场景

- 乐观锁：总认为不会发生并发冲突，允许多个事务同时对数据进行变动，因此不会上锁，只在提交操作时检查是否违反数据完整性。

  - 实现方式：一般使用版本号机制或CAS算法实现。
    - version机制：给数据表加一个版本号version字段，数据被修改时，version+1。事务要更新数据时读取数据及version值，在提交更新时，若当前数据库中的version和刚才读到的version相等，才更新操作，否则重试更新操作
    - CAS（compare and swap）：无锁算法，非阻塞同步。涉及3个操作数，数据所在的内存值、预期值、新值。需要更新时，判断当前内存值与之前取到的值是否相等，若相等（说明内存中的值没被别的线程改过）则用新值更新，若失败则重试

  - 优：不在数据库上加锁，任何事务都可以对数据进行操作，在更新时才进行校验，避免了悲观锁造成的吞吐量下降的问题
  - 缺：人为实现的，仅适用于自己的业务，若有外来事务插入，可能发生错误
  - 适用于：多读场景（此时冲突很少发生，乐观锁省去了锁的开销，加大系统吞吐量）

#### MVCC 多版本并发控制

MVCC为表提供了额外的隐藏字段，记录当前行创建的版本号，删除时的版本号（可能为空）和回滚指针，确保

1. 查找版本早于当前事务版本
2. 行的删除操作的版本要么未定义（未删除），要么大于当前事务的版本号（说明事务A读之前该数据未被删除）

这样即使其他事务在A读之后进行了insert，delete提交，都不会影响A的读取，从而解决了幻读。

ReadView记录系统中当前活跃着的读写事务（start了但是还未commit的事务），以此判断记录的某个版本对当前事务是否可见

> 假设当前列表里的事务id为[80,100]。
>
> 1. 如果要访问的记录版本的事务id为50，比当前列表最小的id80小，那说明这个事务在之前就提交了，所以对当前活动的事务来说是可访问的。
> 2. 如果要访问的记录版本的事务id为70,发现此事务在列表id最大值和最小值之间，那就再判断一下是否在列表内，如果在那就说明此事务还未提交，所以版本不能被访问。如果不在那说明事务已经提交，所以版本可以被访问。
> 3. 如果要访问的记录版本的事务id为110，那比事务列表最大id100都大，那说明这个版本是在ReadView生成之后才发生的，所以不能被访问。这些记录都是去版本链里面找的，先找最近记录，如果最近这一条记录事务id不符合条件，不可见的话，再去找上一个版本再比较当前事务的id和这个版本事务id看能不能访问，以此类推直到返回可见的版本或者结束。

已提交读：事务在每次查询开始都会生成一个独立的ReadView

可重复读：在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView



#### MVCC（多版本并发控制）

[innodb MVCC实现原理](https://zhuanlan.zhihu.com/p/52977862?utm_source=wechat_session&utm_medium=social&utm_oi=772721587307712512)

MVCC是在并发访问数据库时，通过对数据做多版本管理，避免因为写锁的阻塞而造成读数据的并发阻塞问题。

通过保存数据的历史版本，根据比较版本号来处理数据的是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果

1. 事务版本号：每次事务开启前都会从数据库获得一个自增长的事务ID，可以从事务ID判断事务的执行先后顺序。
2. 表的隐藏列（3个）
   - **DB_TRX_ID:** 记录操作该数据事务的事务ID；
   - **DB_ROLL_PTR：**指向上一个版本数据在undo log 里的位置指针；
   - **DB_ROW_ID:** 隐藏ID ，当创建表没有合适的索引作为聚集索引时，会用该隐藏ID创建聚集索引;
3. undo log：记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。
4. read view：在innodb 中每个SQL语句执行前都会得到一个read_view。(保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号)
   - **trx_ids:** 当前系统活跃(未提交)事务版本号集合。
   - **low_limit_id:** 当前系统的最大事务ID+1，创建当前read view 时“当前系统最大**事务版本号**+1”。
   - **up_limit_id:** 最小活跃事务ID，创建当前read view 时“系统正处于**活跃事务**最小版本号”
   - **creator_trx_id:** 创建当前read view的事务版本号；

分情况讨论：

1. **数据事务ID <up_limit_id，显示** ，数据事务ID小于read view中的最小活跃事务ID，说明该数据是在当前事务启之前就已经存在了的,所以可以显示。
2. **数据事务ID>=low_limit_id，不显示**，数据事务ID>read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不予显示
3. **up_limit_id <**数据事务ID<**low_limit_id 则与活跃事务集合**trx_ids**里匹配**，此时这个数据有可能是在当前事务开始的时候还没有提交的，因此需要把数据的事务ID与当前read view 中的活跃事务集合trx_ids 匹配:
   - 如果事务ID不存在于trx_ids 集合（则说明read view产生的时候事务已经commit了），这种情况数据则可以显示.
   - 如果事务ID存在trx_ids则说明read view产生的时候数据还没有提交，但是如果数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。
   - 如果事务ID既存在trx_ids而且又不等于creator_trx_id那就说明read view产生的时候数据还没有提交，又不是自己生成的，所以这种情况下此数据不能显示。

不满足条件时从undo log中获取数据，然后数据历史版本事务号回头再来和read view 条件匹配 ，直到找到一条满足条件的历史数据，或者找不到则返回空结果；





#### 用过什么数据库？各个数据库的应用场景。

### 数据库引擎

存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能。

**一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求**，使用合适的存储引擎，将会提高整个数据库的性能 。

InnoDB 现在是 MySQL 默认的存储引擎，支持**事务、行级锁定和外键**

#### InnoDB 和 MyISAM 的区别

|                                    | MyISAM                                                       | InnoDB                                                       |
| ---------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 事务                               | 不支持                                                       | 支持                                                         |
| 崩溃后安全恢复                     | 不能                                                         | 能                                                           |
| 外键                               | 不支持                                                       | 支持                                                         |
| 最小锁粒度                         | 表锁（table-level locking，一个更新语句会锁住整个表，导致其它查询和更新都被阻塞，不适合高并发操作） | 行锁（row-level locking，操作时只锁某一行，不对其他行产生影响，适合高并发操作） |
| MVCC                               | 不支持                                                       | 支持                                                         |
| 索引                               | 非聚簇索引                                                   | 聚簇索引                                                     |
| 表主键                             | 允许没有任何索引和主键的表存在                               | 若没有设定主键或非空唯一索引，就会自动生成一个6字节的主键（用户不可见） |
| 存储结构                           | 三个文件：表定义文件(.frm)、数据文件(.MYD)、索引文件(.MYI)   | 所有表都存在一个数据文件中（表的大小之受限于操作系统文件的大小，一般为2GB） |
| `select count(*) from table; `速度 | 快（用一个变量保存了整个表的行数，执行该语句只需要读出该变量即可） | 不保存表的具体行数（与MVCC有关），执行该语句时需要全表扫描   |
| 应用场景                           | 管理非事务表，提供高速存储和检索及全文搜索能力。在应用中需执行大量select操作，或表比较小，且可以忍受修复操作 | 用于事务处理，在应用中执行大量insert和update操作             |

> 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？

如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失；

如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。



#### InnoDB为什么要用自增id作为主键

- 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页
- 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置， 频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE（optimize table）来重建表并优化填充页面。
  

### 索引

- 优点

大大加快数据的检索速度，提高系统性能

- 缺点

时间：创建和维护索引需要时间，对表的增加、删除、修改需要动态维护索引

空间：需要额外的物理空间

#### 索引类型

- 主键索引`primary key`：一个表只能有一个主键，且不能为空。一般在建表同时创建
- 唯一索引`unique index`：索引列的值唯一，但允许为空（如果是组合索引，列值的组合必须唯一）
- 普通索引`index`：没有任何限制，用于加速查询
- 全文索引`fulltext`：用于查找文本中的关键字，而不是直接与索引中的值相比较，更像一个搜索引擎



#### 聚集索引 vs 非聚集索引

主索引：主键索引，键值不能重复； 辅助索引：非主键索引，普通索引，键值可重复

- 聚簇索引（将数据存储与索引放在一起）
  - InnoDB的**数据文件本身就是主键索引文件**（按B+树组织的索引结构文件），一个表只能有一个聚簇索引
  - 聚簇索引文件放在主键索引的叶子节点上，因此InnoDB**必须有主键**（推荐整型自增主键），通过主键索引效率很高。
  - 存储内容：InnoDB引擎索引结构的**叶节点存放的就是实际的数据记录**（主索引叶节点存储的是表中所有的数据记录，辅助索引叶节点存储的是主键值<保证数据一致性、节省存储空间>）。
  - 数据查找流程：不管是主键索引还是辅助索引，都需先查找索引节点，才能拿到相应的数据。辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不宜过大，否则其它索引也会很大。
- 非聚集索引（将数据存储与索引分开）
  - 索引文件和数据文件分离
  - 存储内容：MyISAM引擎索引的叶节点存放的是**数据记录的地址**（而不是实际数据记录）。主键索引和辅助索引相互独立。
  - 通过索引查找数据流程：从索引文件中查找到索引节点->从中拿到数据的文件指针->到数据文件中通过文件指针定位具体数据

#### 索引的数据结构

B+树索引：所有叶节点

hash索引：底层的数据结构就是哈希表，在绝大多数需求为单条记录查询时可以选择哈希索引，查询性能最快。但是不支持范围查询、

#### 为什么B+树比B树更适合应用于数据库索引和操作系统的文件索引？
- B+树的磁盘读写代价更低。B+树只有叶子节点才存储数据，非叶节点只存储关键字信息，每个非叶节点（可理解为数据页）能容纳的关键字数量也越多，相对来说树的高度降低，磁盘I/O的读写次数也降低了
- B+树的查询效率更加稳定。任何关键字的查找都必须走一条从根节点到叶节点的路径，因此所有关键字查询的路径长度相同，使得每个数据的查询效率相当
- B+支持基于范围的查询。B+树在叶子节点中是双向链表，且在链表的头节点和尾节点也是循环指向的，因此只要遍历叶节点就可以实现整棵树的遍历。B树只适合随机检索

数据库索引存储在磁盘上，当数据量大时，不能把整个索引加载到内存中，只能逐个加载每个磁盘页（对应索引树的节点）。

[不懂数据库索引的底层原理？那是因为你心里没点b树](http://www.17coding.info/article/25)
#### MySQL 索引的作用和实现

创建索引的原则

1. 最左前缀匹配原则，组合索引时，mysql会一直向右匹配知道遇到范围查询(<,>,between,like)就停止匹配
2. 对较频繁作为查询条件的字段创建索引
3. 定义有外键的列要建索引
4. 更新频繁的字段不适合创建索引
5. 不能有效区分数据的列不适合做索引（eg.性别）
6. 尽量扩展索引，不要新建索引（如已经有了a索引，现在加(a,b)的索引，只需修改原来的索引即可）
7. 定义为text、image、bit的数据类型列不要建索引

#### 对于 SELECT id, age FROM user WHERE status = 0 and age > 12; 这条语句，怎样建立索引比较好？


#### 在 MySQL 中，怎么知道一条语句是否使用了索引？
`explain`+SQL 语句
（1）可以查看表的读取顺序；（2）可以查看数据读取操作的操作类型；（3）可以查看哪些索引可以使用；（4）可以查看哪些索引被实际使用；（5）可以查看表与表之间的引用关系；（6）可以查看每张表有多少行记录被优化器查询。

type：all 表示这条查询遍历了所有行，没有使用索引；其他（如const, eq_ref, ref, range, index等）都会用到索引
key：表示实际使用的索引，NULL表示没有使用索引


#### 索引失效的原因

>  如果一条语句的查询关键字包含了索引中的关键字，但是 MySQL 引擎还是没有使用索引，有可能是什么原因？[字客1]

- 条件中有or，索引失效【可以改成union/union all】 （要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引）
- 复合索引，但是没有用到左列字段
- like以%开头
- where中索引列有运算、函数、(手动/自动)类型转换[字符串不加单引号等]
- mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
- 数据很少，MySQL觉得全表扫描更快

- 存储引擎不能使用索引范围条件右边的列 (`select * from myTest  where a>4 and b=7 and c=9;` a用到了  b没有使用，c没有使用)
- 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少`select *


#### 索引优化策略
- 最左前缀匹配原则
- 主键外键一定要建索引
- 对 where, on, group by, order by 中出现的列使用索引
- 尽量选择区分度高的列作为索引,区分度的公式是`count(distinct col)/count(*)`，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0
- 对较小的数据列使用索引,这样会使索引文件更小,同时内存中也可以装载更多的索引键索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
- 为较长的字符串使用前缀索引
- 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可
- 不要过多创建索引, 权衡索引个数与DML之间关系，DML也就是插入、删除数据操作。这里需要权衡一个问题，建立索引的目的是为了提高查询效率的，但建立的索引过多，会影响插入、删除数据的速度，因为我们修改的表数据，索引也需要进行调整重建
- 对于like查询，”%”不要放在前面。 
`SELECT * FROM user WHERE username LIKE 'Jack%' `-- 走索引 
` SELECT * FROM user WHERE username LIKE '%Jack%' `--- 不走索引查询
- where条件数据类型不匹配也无法使用索引 (eg字符串与数字比较不使用索引)
- 正则表达式不使用索引,这应该很好理解,所以为什么在SQL中很难看到regexp关键字的原因
### 触发器
由事件触发某个操作，事件包括insert、update、delete语句，触发器用于加强数据的完整性约束和业务规则等

- 行级触发器是对DML语句影响的每个行执行一次，如UPDATE语句影响多行，就会对每行都激活一次触发器。
- 语句级触发器是对每个DML语句执行一次，如INSERT语句在表中即使插入了100多行，表上的INSERT语句级触发器也只会执行一次。


**触发器应用场景**：
1. 当向一张表中添加或删除记录时，需要在相关表中进行同步操作。
比如，当一个订单产生时,订单所购的商品的库存量相应减少。

2. 当表上某列数据的值与其他表中的数据有联系时。
比如，当某客户进行欠款消费，可以在生成订单时通过设计触发器判断该客户的累计欠款是否超出了最大限度。

3. 当需要对某张表进行跟踪时。
比如，当有新订单产生时，需要及时通知相关人员进行处理，此时可以在订单表上设计添加触发器加以实现





## 算法

### 常用的数据结构

- 数组：频繁查询，对存储空间要求不大，很少增加和删除的情况。
- 栈：只能在某一端插入和删除的特殊线性表，先进后出。栈常应用于实现递归功能方面的场景，例如斐波那契数列。
- 队列：一种特殊的线性表，它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作。先进先出，从一端放入元素的操作称为入队，取出元素为出队。在多线程阻塞队列管理中非常适用。
- 链表：物理存储单元上非连续的、非顺序的存储结构，每个元素包含两个结点，一个是存储元素的数据域 (内存空间)，另一个是指向下一个结点地址的指针域。根据指针的指向，链表能形成不同的结构，例如单链表，双向链表，循环链表等。适合需要频繁增加，删除操作的场景，不适合频繁查询
- 树： mysql的数据库索引结构用的就是B+树，还有HashMap的底层源码中用到了红黑树
- 散列表：根据关键码和值 (key和value) 直接进行访问的数据结构
- 堆：因为堆有序的特点，一般用来做数组中的排序，称为堆排序
- 图：是由结点的有穷集合V和边的集合E组成

#### 数组 vs 链表

逻辑结构：这两种数据结构都属于线性表。

存储位置：在内存中，数组是一块连续的区域；链表是一种物理存储单元上非连续、非顺序的存储结构

存储空间：一般情况下，存储相同的数据，数组占用的内存较少，而链表由于需要存储指针，需要更多的内存

长度可变性：数组的长度在定义的时候给定，如果存储的数据个数超过数组的原始长度，会发生溢出；而链表的长度可以按实际情况伸缩

按序号查找：数组支持随机访问，时间复杂度为O(1)；链表是顺序访问，平均时间复杂度为O(n)

按值查找：如果序列是无序的，数组和链表的时间复杂度均为O(n)；若序列有序，使用数组可以通过二分查找将时间复杂度降为O(logn)

插入/删除：数组平均需要移动n/2个元素；而链表只需要修改指针

空间分配：数组采用静态存储分配时，存储元素的数量有限，动态存储分配时，存储空间可以扩充，但需要移动大量的元素，导致操作效率较低，而且如果内存中没有更大块的连续存储空间，将导致分配失败；而链表中的元素空间只在需要时分配，只要内存有空间就可以分配，操作比较灵活高效。



#### 栈 vs 队列

栈与队列的相同点：
1.都是线性结构。
2.插入操作都是限定在表尾进行。
3.都可以通过顺序结构和链式结构实现。、
4.插入与删除的时间复杂度都是O（1），在空间复杂度上两者也一样。
5.多链栈和多链队列的管理模式可以相同。
栈与队列的不同点：
1.删除数据元素的位置不同，栈的删除操作在表尾进行，队列的删除操作在表头进行。
2.应用场景不同；常见栈的应用场景包括括号问题的求解，表达式的转换和求值，函数调用和递归实现，深度优先搜索遍历等；常见的队列的应用场景包括计算机系统中各种资源的管理，消息缓冲器的管理和广度优先搜索遍历等。
3.顺序栈能够实现多栈空间共享，而顺序队列不能。



### 查找算法

- **1 顺序查找**
- **2 二分查找**
- **3 插值查找**
- **4 斐波那契查找**
- **5 树表查找**
- **6 分块查找**
- **7 哈希查找**

1. 顺序查找：从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。**时间复杂度为O(n)**

2. 二分查找：**元素必须是有序的，如果是无序的则要先进行排序操作。** 用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。

   **复杂度分析：**最坏情况下，关键词比较次数为 ![[公式]](https://www.zhihu.com/equation?tex=log_2%28n%29%2B1) （ ![[公式]](https://www.zhihu.com/equation?tex=log_2%28n%29) 取下整），且**期望时间复杂度为** ![[公式]](https://www.zhihu.com/equation?tex=O%28log_2n%29) ；

3. 差值查找：**对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。**

   **复杂度分析：查找成功或者失败的时间复杂度均为** ![[公式]](https://www.zhihu.com/equation?tex=O%28log_2%28log_2n%29%29) **。**

4. 斐波那契查找

5. 树表查找

   二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。二叉查找树平均查找性能不错，为O(logn)，但是最坏情况会退化为O(n)。**对二叉查找树进行中序遍历，即可得到有序的数列。**

6. 分块查找

7. 哈希查找



平衡二叉树（AVL）：一个根节点的左右子树的高度差不超过1

查找二叉树：每个根节点大于左子树的任意一个节点，小于等于右子树上的任意一个节点

最长路径不超过最短路径的两倍

根节点为黑色的，叶子节点都是黑色的，每个红色节点的父节点和子节点都是黑色的

从根节点到叶节点路径中黑节点的数目是相等的



### 排序算法

比较类排序（8种）：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序。

非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。 

<img src="https://img2018.cnblogs.com/blog/849589/201903/849589-20190306165258970-1789860540.png" alt="img" style="zoom: 33%;" />

<img src="https://images2018.cnblogs.com/blog/849589/201804/849589-20180402133438219-1946132192.png" alt="img" style="zoom: 33%;" />

[稳定排序和不稳定排序](https://www.cnblogs.com/codingmylife/archive/2012/10/21/2732980.html)

#### 比较类排序算法
稳定：冒泡排序、插入排序、归并排序
不稳定：快速排序、希尔排序、堆排序、选择排序
- 交换排序

  - **冒泡排序**：从头至尾依次比较相邻两个数的大小，如果第一个数大于第二个数，则交换两个数，遍历一遍后，最大的数会在最末尾。

    - 时间复杂度：平均：$O(n^2)$，最坏：$O(n^2)$<逆序>，最好O(n)<顺序，设置flag>
    - 空间复杂度：O(1)；**稳定**

  - **快速排序**：首先从序列中选出一个元素当作基准，通过一趟排序将所有比基准值小的元素都放在基准前面，所有比基准值大的元素都在基准的后面，然后分别对这两个部分进行相同的排序操作，以达到整个序列有序。

    - 时间复杂度：平均：O(nlogn)，最坏：O(n^2)<数组已经有序，退化为冒泡>，最好$O(nlogn)$

      【快速排序最优的情况就是每一次取到的元素都刚好平分整个数组。 此时的时间复杂度公式则为：T[n] = 2T[n/2] + f(n)】

    - 空间复杂度：O(1) ~~采用递归算法，最坏：O(n)，最好O(logn)~~

    - **不稳定**：如果基准点是相等元素中的一个，那么可能出现不稳定。比如[2,2‘,1,3]，如果以第一个2为基准点，将所有小于等于基准值的数都放在基准点前面，那么就有可能出现不稳定的情况。



- 插入排序

  - **简单插入排序**：在待排序的序列中，假定前n-1个数已经排序，通过从后往前扫描将第n个数据插入有序序列中（相当于理扑克牌）

    【稳定】如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变

  - **希尔排序**：将整个待排序的序列根据某一步长分成若干个子序列，对子序列分别进行插入排序。然后逐渐减小步长至1

    按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是**不稳定**的。

  在希尔排序开始时增量较大，分组较多，每组的记录数目少，故各组内直接插入较快，后来增量di逐渐缩小，分组数逐渐减少，而各组的记录数目逐渐增多，但由于已经按di-1作为距离排过序，使文件较接近于有序状态，所以新的一趟排序过程也较快。

- 选择排序【不稳定】

  - 简单选择排序：每次都在待排序序列中，选择最小/最大的数放在最前面（性能不受输入数据的影响）

    按照找最小值，与无序区首部交换的思想则不稳定：在一趟选择，如果一个元素比当前元素小，而且这个小的元素又出现在和当前元素相等的一个元素后面，那么交换后稳定性就被破坏了

    排序前：2,4,4‘,3      排序后：2,3,4’,4

  - 堆排序：利用堆的数据结构设计的。子节点的值总是小于父节点的值。将n个待排序的数构建成大顶堆，此时序列的最大值就是堆顶元素，将其与最后一个元素交换，此时末尾就是最大值。然后将剩余的n-1个元素调整为新的大顶堆，这样堆顶元素就是次大值。如此反复执行就能得到一个有序序列。

- 归并排序

  - 归并排序：（分治）将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再合并两个已经有序的子序列成为一个有序序列。
    - 性能不受输入数据的影响
    - 时间复杂度O(nlogn)，空间复杂度是O(n)，**稳定**

#### 非比较类排序算法

- 计数排序：将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。（每个桶只存储单一键值）
  - 稳定的排序算法。当输入的元素是 n 个 0到 k 之间的整数时，时间复杂度是O(n+k)，空间复杂度也是O(n+k)，其排序速度快于任何比较排序算法。当k不是很大并且序列比较集中时，计数排序是一个很有效的排序算法。

- 桶排序：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。（每个桶存储一定范围的数值）
  - 桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 
- 基数排序：基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。（根据键值的每位数字来分配桶）

稳定性：对于两个相等的元素a,b，排序前a在b前面，排序后a仍在b前面



### 深度优先搜索（DFS）回溯 采用栈

1. 首先任意找一个未被遍历过的顶点，例如从 V1 开始，由于 V1 率先访问过了，所以，需要标记 V1 的状态为访问过；
2. 然后遍历 V1 的邻接点，例如访问 V2 ，并做标记，然后访问 V2 的邻接点，例如 V4 （做标记），然后 V8 ，然后 V5 ；
3. 当继续遍历 V5 的邻接点时，根据之前做的标记显示，所有邻接点都被访问过了。此时，从 V5 回退到 V8 ，看 V8 是否有未被访问过的邻接点，如果没有，继续回退到 V4 ， V2 ， V1 ；
4. 通过查看 V1 ，找到一个未被访问过的顶点 V3 ，继续遍历，然后访问 V3 邻接点 V6 ，然后 V7 ；
5. 由于 V7 没有未被访问的邻接点，所有回退到 V6 ，继续回退至 V3 ，最后到达 V1 ，发现没有未被访问的；
6. 最后一步需要判断是否所有顶点都被访问，如果还有没被访问的，以未被访问的顶点为第一个顶点，继续依照上边的方式进行遍历。

### 广度优先搜索（BFS）采用队列

广度优先搜索类似于树的层次遍历。从图中的某一顶点出发，遍历每一个顶点时，依次遍历其所有的邻接点，然后再从这些邻接点出发，同样依次访问它们的邻接点。按照此过程，直到图中所有被访问过的顶点的邻接点都被访问到。





## 语言的区别

#### 说说C++和python你认为有什么区别[字客1]

- 语言类型：C++为编译型语言；python为解释型的脚本语言。
- 效率：C++效率更高。同样的功能，或许python可以很快的写出代码，但运行所需的时间需要成倍于C++。Python底层的源代码其实可以理解为C语言的一些常用功能的库（如hashmap实现的dict），Python进程就是加载了这些库然后读取配置文件(Python代码)执行相应的逻辑。相同的功能，Python进行了一次转义，肯定会比直接用C实现要慢
- 编程难易：Python编程简洁直接清晰
- 可扩展性：Python语言的底层是C和C++写的，因此程序中某型关键且运算量巨大的模块，设计者可以运用C和C++编写，并在Python中直接调用。这样可以极大的提高运行速度，同时还不影响程序的完整性。
- 数据结构：python提供多种数据结构并精简了冗长部分。C 和 C++ 中，数据的处理往往采用数组或链表的方式，但数组只能存储同一类型的变量 ；链表虽然储存的内容可变，但结构死板，插入删除等操作都需遍历列表，可以说极其不方便。针对这点 Python 提供了丰富的数据结构，包括列表、元组、字典，以及 Numpy 拓展包提供的数组、Pandas 拓展包提供的Data Frame 等。这些数据类型各有特点，可以极大地减少程序的篇幅，使逻辑更加清晰，提高可读性。
- Python中没有专门的char数据类型

#### C++和python在内存管理上有什么区别  

#### C++ vs java

https://blog.csdn.net/break_cycle/article/details/77113812

